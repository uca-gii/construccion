## √çndice

- [Slides de teor√≠a para DevOps - Cultura DevOps](#slides-de-teor√≠a-para-devops-cultura-devops)
- [Slides de teor√≠a para DevOps - CI/CD](#slides-de-teor√≠a-para-devops-cicd)
- [Slides de teor√≠a para 'DevOps' - Branching patterns](#slides-de-teor√≠a-para-devops-branching-patterns)
- [Pr√°cticas de Sistemas de Control de Versiones](#pr√°cticas-de-sistemas-de-control-de-versiones)
- [Pr√°cticas de Terraform para Infraestructura Docker](#pr√°cticas-de-terraform-para-infraestructura-docker)
- [Pr√°cticas de Jenkins](#pr√°cticas-de-jenkins)
- [Gitflow](#gitflow)

<!-- Source: cultura.md -->
# CULTURA DEVOPS


**¬øQu√© es DevOps?**


## ¬øQu√© es DevOps?

![Background image](./img/devops-venn.png)

- **Dev**elopment + **Op**erations

  - Concepci√≥n ‚áæ Desarrollo ‚áæ Entrega
  - Desarrolladores: innovaci√≥n y agilidad
  - Sysadmin: garant√≠as y estabilidad

- **Agilidad**: _Lean manufacturing_

  - La agilidad llega a los procesos de negocio
  - Falta incluir a los sysadmin

El foco principal de DevOps es maximizar el flujo de creaci√≥n de software: desde la concepci√≥n, hasta el desarrollo y la entrega.

- Los desarrolladores quieren innovar y entregar m√°s r√°pido
- Los sysadmin quieren garantizar la estabilidad de los sistemas en producci√≥n y la calidad de los cambios

La cultura DevOps  es un conjunto de pr√°cticas que reducen las barreras entre desarrolladores y operaciones.

- Los desarrolladores est√°n acostumbrados a procesos √°giles, como Scrum y XP, para reducir los tiempos de entrega.
- Pero los procesos √°giles ya involucran tambi√©n a los equipos de negocio
- Sin embargo, falta incluir a los de operaciones en estos equipos

La cultura DevOps es como una extensi√≥n de los procesos √°giles a todos los equipos, tanto desarrolladores como negocios y operaciones.

- DevOps est√° muy influenciado por la tendencia al lean manufacturing


| üìô | Definiciones |
----:|:----
**Desarrollo** |  Se refiere al proceso de crear software, donde los desarrolladores escriben y actualizan el c√≥digo fuente de las aplicaciones.
**Operaciones** | Se centran en la gesti√≥n y mantenimiento de los sistemas y la infraestructura en los que se ejecuta el software. Incluye tareas como la configuraci√≥n, el monitoreo y la resoluci√≥n de problemas.


## ¬øQu√© es DevOps?

<iframe width="1000" height="684" src="https://www.youtube-nocookie.com/embed/Xrgk023l4lI" title="DevOps In 5 Minutes | What Is DevOps?| DevOps Explained | DevOps Tutorial For Beginners |Simplilearn" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>


## Elementos clave para la comunicaci√≥n y colaboraci√≥n

- **Deployment** (despliegues) frecuentes
- Pruebas autom√°ticas
  - TDD: _Test-driven design_
  - BDD: _Behavior-driven design_
- CI/CD: _Continuous **Integration** + Continuous **Delivery**_
- Feedback de usuarios
- Monitorizaci√≥n de apps/infraestructura

Para facilitar la colaboraci√≥n y comunicaci√≥n entre Devs y Ops hacen falta varias cosas:

- Despliegues frecuentes
- Automatizar las pruebas unitarias y de integraci√≥n, con TDD y BDD.
- Pr√°cticas de integraci√≥n y entrega continuas (CI/CD)
- Recopilar el feedback de los usuarios tras cada nuevo despliegue.
- Monitorizar las aplicaciones y la infraestructura.


**¬øQu√© significan **integraci√≥n**, **entrega** (_delivery_) y **despliegue** (_deployment_)?**


_On your marks, get set,... go!_

![Background image](img/on-your-marks.jpg)

>[!NOTE]
>El despliegue es el "¬°ya!" en "preparados, listos... ¬°ya!"

La integraci√≥n podr√≠a ser el "¬°a sus puestos!"


| üìô | Definiciones |
----:|:----
 ****Integraci√≥n****  continua   | Llevar autom√°ticamente los cambios de **varios desarrolladores** en el c√≥digo de una aplicaci√≥n a un **repositorio** compartido para cada nueva versi√≥n.
 ****Entrega****  continua  | Trasladar la aplicaci√≥n de software desde el entorno de desarrollo y dejarla **disponible para** su despliegue en un entorno de producci√≥n. Incluye pruebas, empaquetado y preparaci√≥n de cada _**release**_.
****Despliegue****    | Instalaci√≥n de una aplicaci√≥n en su entorno de **producci√≥n**, ya sea en un servidor, un conjunto de servidores, un contenedor, la nube, etc.


**¬øDevOps es un nuevo rol?**

![Background image](img/superhero.png)

>[!NOTE]
>Muchos piensan que DevOps es un rol de TI, un h√≠brido entre desarrollador y administrador de sistemas.

El problema de este pensamiento es que las empresas tienden a crear un nuevo silo llamado DevOps e intentan llenarlo con superadministradores que saben m√°gicamente de ambas cosas.


## ¬øQu√© no es DevOps?

- Es una **cultura**, no un rol

  - Si fuese un rol $\Rightarrow$ nuevo n√∫cleo aislado (silo)
  - No son superhumanos

- Responsabilidades: **desarrollo** (c√≥digo), **calidad** (pruebas) y **operaciones** (sysadmin)
  - No exclusivas
  - Proceso colaborativo

M√°s que un rol, DevOps es un cambio cultural en la forma en que se crea software.

El objetivo no es contratar personas superhumanas, sino construir sistemas con una nueva mentalidad:

- Las necesidades de desarrollo, calidad y operaciones est√°n interrelacionadas. Los desarrolladores ya no ser√°n responsables solo del c√≥digo, los probadores solo de las pruebas y los sysadmins solo de la operaci√≥n del sistema.

- Deben formar parte de un proceso colaborativo

DevOps est√° m√°s centrado en la colaboraci√≥n entre equipos que en la creaci√≥n de un nuevo rol.

DevOps es m√°s una cultura, indica qu√© conseguir. Pero habitualmente se suele mezclar con el c√≥mo y se convierte en un rol.


**¬øPor qu√© DevOps?**


## Motivaci√≥n

- Sistemas fr√°giles

  $\Leftarrow$ Falta de comunicaci√≥n y herramientas

  $\Rightarrow$ Despliegues complejos y propensos a errores

- Deuda t√©cnica

- Arquitectura poco s√≥lida
- Requisitos no funcionales poco solventes

>[!NOTE]
>El movimiento DevOps surgi√≥ de la frustraci√≥n de muchos profesionales que trabajaban con sistemas fr√°giles.

Fr√°giles porque el software se construye en silos donde los diferentes equipos no se comunican entre s√≠ de una forma eficaz.

Debido a esta falta de comunicaci√≥n, los desarrolladores no suelen disponer de entornos y herramientas para ser productivos, y el equipo de operaciones suele recibir el software como un "ah√≠ llevas eso" (para que le des soporte).

Los despliegues son complejos y propensos a errores.

Los sistemas, cargados de deuda t√©cnica, originan un trabajo no planificado.

Los desarrolladores se ven obligados a tomar atajos, que suelen dar lugar a una arquitectura poco s√≥lida y un retraso en los requisitos no funcionales, como la seguridad y la mantenibilidad.


![Background image](img/punch.png)


| üìô | Definiciones |
----:|:----
 **Deuda t√©cnica   | Decisiones tomadas durante el desarrollo de un software que, en el corto plazo, permiten un desarrollo m√°s r√°pido o una soluci√≥n temporal, pero que crean problemas de NFR a largo plazo
 <emph>Requisitos No Funcionales (NFR) | Aspectos que no est√°n relacionados directamente con la funcionalidad de un sistema software, sino con caracter√≠sticas no directamente vinculados a sus funciones espec√≠ficas (rendimiento, usabilidad, confiabilidad, seguridad, eficiencia, etc.)
 <emph>Arquitectura software | Estructura y dise√±o organizativo de un sistema de software, sobre c√≥mo sus <emph>componentes** interact√∫an entre s√≠ y c√≥mo se organizan para lograr sus objetivos de manera efectiva. Proporciona un marco conceptual para abordar aspectos de los NFR.


## Cultura DevOps

![Background image](img/devops-culture.png)

[Definici√≥n de Donovan Brown](https://www.donovanbrown.com/post/what-is-devops)

> DevOps es la uni√≥n de personas, procesos y productos para una entrega continua de valor a los usuarios finales

- Procesos con Agilidad
- Personas en Colaboraci√≥n
- Productos con Herramientas

>[!NOTE]
>¬øCu√°l es el proceso? Muy similar a los procesos √°giles, incluyendo los elementos clave descritos antes: CI/CD, monitorizaci√≥n, etc.

¬øQu√© hacen las personas? Colaborar, comunicarse y compartir responsabilidades.

¬øC√≥mo se crea el producto? Usando herramientas que automaticen todos los elementos del proceso y faciliten la colaboraci√≥n y la comunicaci√≥n.


## CI/CD: Continous Integration / Continuous Delivery

![Background image](img/cicd_side.png)

- Continuous integration (CI)
- Continuous delivery (CD)
- Continuous deployment

Cada proceso tiene su propio **pipeline**


### Pipeline de CI

![CI pipeline](img/ci-pipeline.png)

>[!NOTE]
>CI es la pr√°ctica de construir y probar las aplicaciones en cada nueva versi√≥n.


### Pipeline de CD

![CD pipeline](img/cd-pipeline.png)

>[!NOTE]
>CD a√±ade pruebas autom√°ticas y despliegue autom√°tico al proceso de CI.

Gracias a CD, el software entregado debe funcionar siempre.

Todos los cambios que se incorporan en un build pueden formar parte de un candidato a release.

Antiguamente, los cambios peque√±os sol√≠an tener que esperar a que se completaran otros muchos antes de ser empaquetados en una release. Siguiendo ese modelo, se supon√≠a que el software era incorrecto hasta que era validado por profesionales de QA. Todas las pruebas se realizaban despu√©s del desarrollo, la responsabilidad de la calidad reca√≠a exclusivamente en el equipo de QA.


### Continuous Deployment

![CDEP pipeline](img/cdep-pipeline.png)

>[!NOTE]
>El despliegue continuo es la pr√°ctica de desplegar autom√°ticamente el software en producci√≥n despu√©s de cada cambio.

La entrega es manual, el despliegue es autom√°tico.


| üìô | Definiciones |
----:|:----
**Build**   | acci√≥n de compilar y ensamblar el c√≥digo fuente de una aplicaci√≥n en un formato ejecutable o en un conjunto de artefactos que se pueden utilizar en un entorno de ejecuci√≥n espec√≠fico
**Pipeline**   | un conjunto automatizado y secuencial de procesos que permiten la ejecuci√≥n de tareas espec√≠ficas. Analog√≠a de una l√≠nea de montaje de la industria de fabricaci√≥n
**Staging** | entorno de prueba que replica el entorno de producci√≥n para realizar pruebas finales (con usuarios) antes del despliegue


| üìô | Definiciones |
----:|:----
**Artefacto** | resultado del _build_. Pueden ser binarios ejecutables, bibliotecas, paquetes de instalaci√≥n, etc., necesarios para ejecutar la aplicaci√≥n
**Release** | una versi√≥n espec√≠fica y completa de una aplicaci√≥n o software que se considera lista para ser distribuida y utilizada por los usuarios finales
**Release Candidate (RC)** | _release_ con el potencial de convertirse en la versi√≥n final o lanzamiento si no se encuentran problemas significativos durante las pruebas


![Background image](img/devops_practices_side.png)

## Pr√°cticas DevOps

1. Automatizar la infrastructura: **IaC**
2. Automatizar los despliegues: **Provisioning**
3. Medir, monitorizar y experimentar: **Feature flags**


### 1. Automatizar la infrastructura

- **IaC: _Infrastructure as Code_**

  - Automatizar: MV/contenedores
  - Im√°genes _est√°ndar_ (v.g. NGINX + MariaDB + Ruby)
  - Entorno de destino

- Provisioning
- Feature flags

>[!NOTE]
>IaC es el proceso de escribir el c√≥digo de las etapas de aprovisionamiento y configuraci√≥n de los componentes de la infraestructura, lo que ayuda a automatizar su implementaci√≥n de manera repetible y consistente.

La forma de permitir el self-service provisioning es crear un conjunto est√°ndar de im√°genes de m√°quinas que se puedan solicitar bajo demanda. Estas im√°genes representan m√°quinas est√°ndar con todos los controles de seguridad, pol√≠ticas y paquetes de software est√°ndar instalados.

Por ejemplo, un desarrollador que necesira un servidor web con Ruby puede seleccionar, de entre un conjunto est√°ndar de im√°genes de m√°quinas, un servidor de aplicaciones NGINX, un servidor de base de datos MySQL, etc.

El desarrollador no tiene que configurar ninguno de estos entornos. En su lugar, solo tiene que solicitar una imagen y un entorno de destino. El entorno se aprovisiona autom√°ticamente y el desarrollador puede empezar a trabajar.


#### IaC por configuraci√≥n

##### Contenerizaci√≥n e inmutabilidad

**M√°quinas virtuales** (mutables) versus **Contenedores** (inmutables)

##### Ejemplo con Docker

Dockerfile:

```dockerfile
FROM ubuntu
RUN apt-get update
RUN apt-get install -y nginx
ENTRYPOINT ["/usr/sbin/nginx","-g","daemon off;"]
EXPOSE 80
```

>[!NOTE]
>Contenerizaci√≥n = desplegar aplicaciones en contenedores en lugar de desplegarlas en VM.

Es importante que la IaC sea inmutable, es decir, que no se pueda modificar una vez creada. Si se necesita un cambio, se crea una nueva versi√≥n de la imagen. A diferencia de las VMs, los contenedores son inmutables, es decir, la configuraci√≥n de un contenedor no puede modificarse durante su ejecuci√≥n.

v.g.: Dockerfile para especificar la imagen (sistema operativo) base, middleware adicional y configuraci√≥n de red y puertos. Solo contiene los ficheros y binarios necesarios para la aplicaci√≥n.

Esto puede funcionar en una IaaS. Pero tambi√©n en una PaaS, donde los desarrolladores pueden realizar la misma funcionalidad de autoservicio utilizando la interfaz de usuario de la PaaS.


#### IaC con tipos declarativos

- Terraform / OpenTofu
- Vagrant
- Ansible
- Azure ARM template
- Azure Bicep
- PowerShell DSC
- Puppet
- Chef
- Etc.

>[!NOTE]
>Hay lenguajes declarativos en los que es suficiente escribir el estado del sistema o la infraestructura deseada en forma de configuraci√≥n y propiedades.

Este es el caso, por ejemplo, de Terraform y Vagrant de HashiCorp, Ansible, Azure ARM template, Azure Bicep, PowerShell DSC, Puppet y Chef.


**Ejemplo usando terraform** para definir un servicio de AWS con un contenedor de Docker que sirve una p√°gina web en un cluster de ECS (_Elastic Container Service_)

```hcl
provider "aws" {
  region = "West Europe" # Cambia esto seg√∫n tu regi√≥n de AWS
}

resource "aws_ecs_cluster" "example_cluster" {
  name = "example-cluster"
}

resource "aws_ecs_task_definition" "example_task" {
  family                   = "example-task"
  network_mode             = "bridge"
  requires_compatibilities = ["EC2"]
  ...
```


```hcl
  ...
  container_definitions = <<EOF
[
  {
    "name": "example-container",
    "image": "nginx:latest",
    "portMappings": [
      {
        "containerPort": 80,
        "hostPort": 80
      }
    ]
  }
]
EOF
}
...
```


```hcl
...
resource "aws_ecs_service" "example_service" {
  name            = "example-service"
  cluster         = aws_ecs_cluster.example_cluster.id
  task_definition = aws_ecs_task_definition.example_task.arn
  launch_type     = "EC2"
  desired_count   = 1

  network_configuration {
    # Coloca las ID de tus subredes aqu√≠
    subnets         = ["subnet-xxxxxxxxxxxxxx", "subnet-yyyyyyyyyyyyyy"]
    # Coloca la ID de tu grupo de seguridad aqu√≠
    security_groups = ["sg-xxxxxxxxxxxxxxxxx"]
  }
}
```


### 2. Automatizar los despliegues

- IaC: _Infrastructure as Code_

- **Provisioning**

  - Despliegues manuales engorrosos
  - No repetibles. Hay que automatizar

- Feature flags

>[!NOTE]
>En los viejos tiempos, los despliegues eran procesos manuales engorrosos que sol√≠an depender de personas espec√≠ficas que conoc√≠an los pasos necesarios para desplegar un build.

El proceso no era repetible debido a la intervenci√≥n manual requerida y los despliegues eran ejercicios temidos que ocurr√≠an tarde por la noche o temprano por la ma√±ana.

La automatizaci√≥n de los despliegues tiene como objetivo resolver todos estos problemas.


#### Provisioning (aprovisionamiento)

##### Opciones

- PaaS
- Recursos serverless
- Red

##### Herramientas

- terraform
- Azure ARM template, Azure CLI, Azure PowerShell
- AWS Cloud training
- Google Cloud Deployment Manager
- Etc.

>[!NOTE]
>Aprovisionamiento = creaci√≥n de los recursos que forman la infraestructura.

Puede aprovisionarse un PaaS o un tipo de recurso serverless, como una app web, una Azure function o un Event Hub. Pero tambi√©n puede aprovisionarse la parte de red que se gestiona, como VNet, subnets, tablas de encaminamiento o un cortafuegos de Azure.

Para las VM, solo se crea o actualiza el recurso cloud de la VM, pero no su contenido, que hay que aprovisionar.

Diversas herramientas de aprovisionamiento


#### Buenas pr√°cticas de IaC & provisioning

An√°logas al desarrollo de software:

- Automatizar todo en el c√≥digo, nada manual
- Someter a SCM (_Source Control Manager_) para versionar, rastrear, fusionar y restaurar
- Guardar el c√≥digo de IaC junto al de la aplicaci√≥n (mismo repo)
- C√≥digo de la IaC debe ser **idempotente**
- Integrar con CI/CD

IaC requiere de pr√°cticas an√°logas a la del desarrollo software:

- Todo debe estar automatizado en el c√≥digo: hay que codificar y automatizar todos los pasos de aprovisionamiento y no dejar fuera pasos manuales que distorsionen la automatizaci√≥n de la infraestructura.

- Al igual que el c√≥digo de las aplicaciones, el c√≥digo de la IaC debe estar sometido a un SCM para poder versionarlo, rastrearlo, fusionarlo y restaurarlo. Mejorar visibilidad del c√≥digo entre Devs y Ops.

- El c√≥digo de la IaC debe guardarse junto al c√≥digo de la aplicaci√≥n, si es posible en el mismo repositorio. As√≠ se asegura una mejor organizaci√≥n del trabajo entre desarrolladores y operaciones, que compartir√°n el mismo espacio de trabajo.

- Los scripts deben tener en cuenta el estado de la infraestructura cuando se ejecutan y no generar un error si el recurso que se va a crear ya existe, o si un recurso que se va a eliminar ya se ha eliminado. Los lenguajes declarativos, como Terraform, asumen este aspecto de la idempotencia de forma nativa.

Al igual que los procesos de CI/CD, la IaC es clave en la cultura DevOps. La IaC solo puede ser eficaz con herramientas adecuadas.

Para las pruebas locales de infraestructura, algunas herramientas como Vagrant pueden simular un entorno local.


### 3. Medir, monitorizar y experimentar

- IaC: _Infrastructure as Code_

- Provisioning

- **Feature flags**

  - A/B testing
  - Distintas versiones, geograf√≠as, periodos de tiempo, navegadores, dispositivos, etc.
  - Experimentos en producci√≥n

Ejemplo: supongamos que un product manager tiene la teor√≠a de que el proceso de registro es demasiado complejo para algunos usuarios y quiere probar un nuevo formulario m√°s sencillo. La nueva p√°gina de registro se puede querer configurar para que se muestre cada vez que se solicite, de modo que el equipo pueda comparar las m√©tricas de los usuarios de la nueva p√°gina con las de los usuarios de la p√°gina antigua. La cultura DevOps fomenta este tipo de experimentaci√≥n fail fast.

Las feature flags permiten configurar caracter√≠sticas que se pueden activar o desactivar, o que solo est√©n disponibles para un determinado grupo de usuarios.

Aprovechando las feature flags, podemos ejecutar experimentos como A/B testing para recopilar informaci√≥n y aprender sobre el sistema y sus usuarios.

- Mediante feature flags y configuraciones, se puede configurar que la p√°gina de registro se muestre de un modo que el equipo pueda comparar las m√©tricas de los usuarios de la nueva p√°gina con las de los usuarios de la p√°gina antigua.

- Otra opci√≥n ser√≠a probar una caracter√≠stica en determinadas geograf√≠as, periodos de tiempo, navegadores o dispositivos.

- Las FF tambi√©n se pueden utilizar para probar caracter√≠sticas en producci√≥n con una carga de trabajo real. La caracter√≠stica se puede habilitar para un grupo de prueba o como un lanzamiento beta para una ubicaci√≥n seleccionada. Despu√©s se puede supervisar de cerca y desactivarla una vez que se haya recopilado suficiente informaci√≥n o si se hay problemas.


| üìô | Definiciones |
----:|:----
**IaC** | pr√°ctica en la que la infraestructura de sistemas, redes y otros recursos tecnol√≥gicos se gestiona y **aprovisiona** utilizando c√≥digo y archivos de configuraci√≥n en lugar de realizar configuraciones manuales o a trav√©s de interfaces gr√°ficas
**Provisioning** |  proceso de preparar y configurar de manera autom√°tica los recursos de infraestructura necesarios para ejecutar una aplicaci√≥n o servicio
**Feature flags** |  t√©cnica de desarrollo de software que permite habilitar o deshabilitar caracter√≠sticas espec√≠ficas de una aplicaci√≥n durante o despu√©s del despliegue


![Background image](img/12factor-app.png)

## Metodolog√≠a 12-Factor App

- Guia para apps SaaS modernas: portables, escalables, mantenibles.
- Define principios para codebase, configuraci√≥n, dependencias y procesos.
- https://12factor.net/


### 12 factores para apps SaaS modernas

<div class="cols">
<div>

1. **Codebase**: una base de codigo por app, versionada.
2. **Dependencies**: declarar y aislar dependencias expl√≠citamente.
3. **Config**: configuraci√≥n fuera del codigo, via variables de entorno.
4. **Backing services**: tratar servicios externos como recursos adjuntos.
5. **Build, release, run**: separar etapas de build y ejecuci√≥n.
6. **Processes**: ejecutar como procesos stateless, sin compartir estado.

</div>
<div>

7. **Port binding**: exponer servicios por un puerto propio.
8. **Concurrency**: escalar por procesos, no por hilos internos.
9. **Disposability**: inicio r√°pido y apagado limpio.
10. **Dev/prod parity**: entornos dev y prod lo m√°s parecidos posible.
11. **Logs**: logs como flujo de eventos, no archivos locales.
12. **Admin processes**: tareas admin como procesos puntuales.

</div>
</div>


![Background image](img/12factor-app.png)

## Metodolog√≠a <br> 12-Factor App

Las herramientas de DevOps y CI/CD (Docker, K8s, etc.) no son solo utilidades aisladas, sino piezas necesarias para cumplir un est√°ndar de arquitectura moderna (SaaS) robusta y escalable.

*   **Factor I (Codebase)**: **Git** y **GitHub/GitLab** como la base del flujo de trabajo y el control de versiones.
*   **Factor III (Config)**: Herramientas como **Ansible** y **Terraform** permiten tratar la IaC y gestionar configuraciones declarativas, aline√°ndose con el mandato de separar la configuraci√≥n del c√≥digo.
*   **Factor V (Build, Release, Run)**: Herramientas como **Jenkins**, **CircleCI** y **GitHub Actions** automatizan la separaci√≥n estricta entre las etapas de construcci√≥n, lanzamiento y ejecuci√≥n que exige el Factor V.
*   **Factor VIII (Concurrency)**: **Kubernetes** como la herramienta para gestionar "pods" y escalar autom√°ticamente, lo cual responde al Factor VIII (Concurrencia mediante el modelo de procesos).
*   **Factor IX (Disposability)**: La capacidad de Kubernetes para recuperar contenedores cuando "las cosas van mal" o realizar "rolling updates" soporta el principio de Desechabilidad (Disposability) de los procesos.
*   **Factor X (Dev/prod parity)**: **Docker** como la soluci√≥n para "empaquetar aplicaciones y dependencias en una unidad estandarizada", eliminando el problema de "funciona en mi m√°quina". Esto es la realizaci√≥n directa del Factor X (Paridad entre desarrollo y producci√≥n).
*   **Factor XI (Logs)**: El stack **ELK** (Elasticsearch, Logstash, Kibana) y **Prometheus** pueden transformar el "caos de los logs" en datos visualizables y centralizados, cumpliendo con el principio de tratar los logs como flujos de eventos (*event streams*) en lugar de archivos est√°ticos.
<!-- Source: cicd.md -->
# INTEGRACI√ìN Y ENTREGA CONTINUAS


## Integraci√≥n Continua

![Background image](img/jordan.jpg)


![Background image](img/jordan.jpg)

**_I've never lost a game,_**
**_I just ran out of time._**

**&emsp; Michael Jordan**

>[!NOTE]
>CI sigue el principio de que si algo cuesta mucho esfuerzo, se debe hacer m√°s a menudo para que sea menos doloroso.


| üìô | Conceptos b√°sicos |
----:|:----
**Control de versiones** | git, cvs, subversion, mercurial, etc.
**Repo** | `uca-gii/construccion` alojado en github
**Mainline** | estado actual del repositorio
**Working copy** | copia local del repositorio
**Check out** | clonar el repositorio en local

¬°Cuidado! A diferencia de otros SCV antiguos, hacer `checkout` en git es cambiar de rama o restaurar los ficheros de un _working tree_.


**¬øC√≥mo funciona CI en la pr√°ctica?**


## Ejemplo de CI a escala

Desarrollo de una nueva caracter√≠stica o _feature_...

### Check-out

Hacer **check-out** de una **working copy** en un **repositorio**

```bash
$ git clone https://github.com/sistemas-sw/construccion
Clonando en 'construccion'...
remote: Enumerating objects: 688, done.
remote: Counting objects: 100% (104/104), done.
remote: Compressing objects: 100% (74/74), done.
remote: Total 688 (delta 45), reused 84 (delta 29), pack-reused 584
Recibiendo objetos: 100% (688/688), 39.75 MiB | 22.49 MiB/s, listo.
Resolviendo deltas: 100% (296/296), listo.
```


Cambiarse al repo con la _working copy_ **local**

```bash
$ tree -d construccion
construccion/
‚îú‚îÄ‚îÄ docs
‚îú‚îÄ‚îÄ marp
‚îî‚îÄ‚îÄ slides
    ‚îú‚îÄ‚îÄ devops
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ docker
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ docs
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ img
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ img
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ jenkins
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ entregable
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ img
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ scv
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ img
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ terraform
    ‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ img
    ‚îú‚îÄ‚îÄ implementacion
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ img
    ‚îî‚îÄ‚îÄ marp
$ cd construccion
```


### Entorno de construcci√≥n

Preparar el entorno de construcci√≥n:

```bash
$ cd marp
$ npm install --save @marp-team/marp-core

added 304 packages, and audited 305 packages in 3s

34 packages are looking for funding
  run `npm fund` for details

found 0 vulnerabilities
```


### Construcci√≥n (_build_)

Construir en local (deber√≠a automatizarse):

```bash
$ cd ..
$ mkdir ./html/img
$ cp -R slides/devops/img/ ./html/img/
$ marp --allow-local-files --config-file ./marp/marp-engine.js \
    --html slides/devops/cultura.md \
    -o ./html/cultura.html
[  INFO ] Converting 1 markdown...
[  INFO ] slides/devops/cultura.md => html/cultura.html
$ open ./html/cultura.html
```


Ignorar el _build_ (carpeta `html/`) al sincronizar el repo:

```bash
$ cat .gitignore
...
# Ignorar la carpeta html/
html/*.html
html/img/*.png
html/img/*.gif
**/html
...
```


### Desarrollo y pruebas

A partir de ahora:

- Modificar _source code_ (ficheros `.md`) para hacer una tarea.
- Hacer tests de que el cambio funciona.
- `git add`, `git commit` y `git push` para subir los cambios al repositorio.

Con git:

- El _index_ guarda una instant√°nea del contenido del _working tree_.
- Hacer _commit_ es grabar los cambios en el repositorio (local).
- Hacer _push_: es subir al repo global


### Colaboraci√≥n con otros

Si alguien modifica algo...

```bash
$ git pull
remote: Enumerating objects: 20, done.
remote: Counting objects: 100% (20/20), done.
remote: Compressing objects: 100% (6/6), done.
remote: Total 15 (delta 9), reused 15 (delta 9), pack-reused 0
Desempaquetando objetos: 100% (15/15), 3.03 KiB | 344.00 KiB/s, listo.
Desde https://github.com/sistemas-sw/construccion
   23141b5..7cc4304  master     -> origin/master
Actualizando 23141b5..7cc4304
Fast-forward
 slides/devops/cicd.md    | 194 ++++++++++++++++++------------------------------
 slides/devops/cultura.md | 184 ++++++++++++++++++-------------------------
 2 files changed, 118 insertions(+), 260 deletions(-)
```


### Intregraci√≥n

A√∫n no hemos acabado... Hay que hacer un build (manual o autom√°tico) en un servidor de integraci√≥n com√∫n (v.g. Jenkins, Github Actions).

- Si hay un conflicto entre dos desarrolladores, se suele detectar cuando el segundo hace un build sobre su copia de trabajo. Hay que arreglarlo lo antes posible.
- El repo debe quedar en todo momento con un software estable, funcional y con pocos errores.
- No hay que alejarse mucho de esa base estable pues llevar√≠a mucho tiempo integrarse con ella.

Martin Fowler: [Building a feature with CI](https://martinfowler.com/articles/continuousIntegration.html#BuildingAFeatureWithContinuousIntegration)


![Background image](img/devops-team.png)

## Beneficios de CI

Abordar problemas del desarrollo:

- Software complejo
- Cambios inesperados e incompatibles
- Desarrollo en equipo

Ventajas:

- Retroalimentaci√≥n r√°pida
- Lotes peque√±os
- Calidad y productividad

Un sistema software es algo muy complejo. Un cambio aparentemente sencillo en un fichero puede tener efectos no deseados en el sistema. Cuando muchos desarrolladores trabajan en un grupo de sistemas relacionados, coordinar los cambios es dif√≠cil, porque los cambios de diferentes desarrolladores pueden ser incompatibles.

Las pr√°cticas de integraci√≥n continua (CI) sirven para abordar estos problemas.

- CI propone crear ciclos de retroalimentaci√≥n r√°pidos para garantizar que los desarrolladores trabajen en lotes peque√±os.
- CI permite a los equipos producir software de calidad, reducir el coste de desarrollo y mantenimiento, y aumentar la productividad.


## Pr√°cticas de CI

- Un solo repositorio de c√≥digo fuente
- Automatizar la construcci√≥n (build)
- Hacer el build self-testing
- Todos deben hacer commit al trunk todos los d√≠as
- Cada commit a la _mainline_ debe originar un build en un servidor de integraci√≥n
- Arreglar inmediatamente los builds fallidos
- Mantener r√°pidos los build
- Etc.

Martin Fowler: [Practices of CI](https://martinfowler.com/articles/continuousIntegration.html#PracticesOfContinuousIntegration)


### Un solo repositorio

![Background image](img/un-solo-anillo.png)

- SCM, CVS, configuration management,...
  - Todo en el **monorepo**...
  - ...menos los productos del build
- Instalar SO, [IDE, SGBD] y... checkout!
- Minimizar n√∫mero de ramas

- SCM, CVS, configuration management,...

- Poner en el repo todo lo necesario para hacer un build desde cero: c√≥digo, test scripts, properties files, database schema, install scripts, third party libraries,... incluso compiladores (!)

- No poner en el repo los productos de un build, solo los scripts para hacerlo

- Antes de hacer un checkout para el build desde cero, quiz√° solo deber√≠a tener que instalarse un SO, un entorno de desarrollo (!) y un SGBD. A veces ni eso.

- Minimizar el n√∫mero de ramas


![Background image](img/automatizar-construccion.png)

### Automatizar los _build_

- Build tools: make, GNU Autotools, Apache ant, mvn, gradle, dotnet msbuild, Ruby rake, etc.
- Dependencias: Apache ivy, maven, npm, yarn, pip, conda, NuGet, cargo, etc.

No depender de los IDEs para hacer builds


### Hacer el build self-testing

![Background image](img/self-testing.png)

- ¬øHacer TDD o XP?
- Suite de tests automatizados
- XUnit, UI tests (Selenium), APIs (Appium), Mocking (mockito), etc.
- SAST (SonarQube, ESLint, etc.)

- No es imprescindible hacer TDD o XP

- Pero hay que tener una suite de tests automatizados. Si falla uno, debe fallar el build

- Empezar con XUnit y seguir con pruebas de interfaz de usuario (Selenium), APIs (Appium), mocking (Mockito), etc.

- Integrar el an√°lisis est√°tico de c√≥digo (SonarQube, ESLint)


### Todos deben hacer commit al trunk todos los d√≠as

![Background image](img/aizkolaris.png)

- Encontrar problemas pronto
- Frecuentes merge de ramas en el trunk
- Diff debugging tras detectar fallos al ejecutar el build:
  [`git bisect`](https://git-scm.com/docs/git-bisect)

- Para arreglar pronto los problemas, hay que encontrarlos pronto. Hacer commit frecuentes ayuda.

- Si se trabaja en una rama, hay que hacer merge con frecuencia con el trunk

- Tambi√©n se detectan conflictos al ejecutar el build: hacer diff debugging (hacer checkout de c√≥digo entre un par de fechas, averiguar cu√°ndo se introdujo el cambio que provoca el fallo y hacer diff para ver qu√© ha cambiado)


#### B√∫squeda binaria de bugs en _commits_ (inicio)

![](img/git-bisect-1.png)

>[!NOTE]
>Primero hay que proporcionarle un commit bueno y uno malo

Mensaje que dice cu√°ntos pasos quedan hasta encontrar el commit malo

Bisecting: X revisions left to test after this (roughly Y steps)


#### B√∫squeda binaria de bugs en _commits_ (repetir pasos)

![](img/git-bisect-2.png)

`$ git bisect reset`

Repetir en cada paso indicando si el bug a√∫n persiste
- Si el bug persiste, git bisect bad
- Si el bug desaparece, git bisect good

Cuando se completan todos los pasos, git muestra el mensaje con el SHA del primer commit malo

Tras encontrar el commit que introdujo el bug, se puede resetear el git bisect


### 1 commit de _mainline_ $\Rightarrow$ 1 build en servidor de integraci√≥n

![Background image](img/worked-my-machine2.png)

- Update y build local... ¬°no siempre se hace!
- Pues en mi m√°quina me funciona...
- Build en m√°quina compartida (manual vs. servidor de integraci√≥n)
- Servidores de CI: Jenkins, Gitlab CI/CD, Teamcity, Bamboo, GitHub Actions, Azure DevOps services, CircleCI, Semaphore, etc.

>[!NOTE]
>Alguien puede no hacer un update y build local antes de hacer commit. Los desarrolladores pueden tener configuraciones diferentes en sus m√°quinas, as√≠ que hay que hacer los build en una m√°quina compartida

En el build manual el desarrollador se conecta y lanza el build.
El servidor de integraci√≥n monitoriza el repositorio, lanza el build cuando hay un commit y notifica al desarrollador

Servidores de CI (algunos solo disponibles en la nube)


**¬ø_Nightly builds_ es hacer integraci√≥n continua?**

>[!NOTE]
>Nightly builds no es hacer CI


### Arreglar inmediatamente los builds fallidos

![Background image](img/failed-build.png)

- Prioridad 1
- Un par de personas basta
- T√©cnica r√°pida: revertir el commit m√°s reciente que ha roto el build y debug en local
- T√©cnica para evitar romper la mainline: crear _working copy_ desde _head_ y hacer _commits_ en una rama **pending-head** diferente

>[!NOTE]
>Prioridad 1:  arreglar un build que falla

No todo el mundo tiene que dejar de hacer lo que est√° haciendo para arreglarlo. Con un par de personas suele ser suficiente. Para poder hacer esto hay que seguir un workflow que lo permita.

Manera r√°pida: revertir el commit m√°s reciente que ha roto el build y hacer debug en local

T√©cnica pending-head para evitar romper el mainline: crear una working copy que se actualiza desde el head verdadero (para mantenerse sincronizado) pero hacer commits en una rama diferente pending-head.


### Mantener r√°pidos los build

![Background image](img/sagrada-familia.png)

- ¬ø1 hora es mucho? ¬ø10 minutos?
- Testing: cuello de botella
- _Build pipeline_ o _Staged build_
- Ejemplo: 2-stage pipeline
  **1¬™ etapa** r√°pida (compilaci√≥n y pruebas unitarias sin la BD) $\rightarrow$  1er. _commit build_
  **2¬™ etapa** lenta (pruebas de integraci√≥n con la BD real) $\rightarrow$  build secundario $\rightarrow$ si falla, a√±adir tests al commit build

>[!NOTE]
>El cuello de botella m√°s habitual es el testing (en particular, si involucran servicios externos como bases de datos): mocking!

Deployment pipeline, aka build pipeline / staged build

Ejemplo two-stage pipeline: 1¬∫ r√°pida (compilaci√≥n y pruebas unitarias sin la BD), 2¬∫ lenta (pruebas de integraci√≥n con la BD real). El primer commit build se hace tras la 1¬™ etapa. Si falla el build secundario tras la 2¬™ etapa, es un s√≠ntoma de que hacen falta m√°s tests en los commit builds.


### Otras pr√°cticas de CI...

- Testear en un clon del entorno de producci√≥n
- Hacer que sea f√°cil para cualquiera obtener el ejecutable m√°s reciente
- Todos pueden ver lo que est√° pasando
- Automatizar el despliegue


## Trunk-Based Development (TBD)

![Background image](img/tbd-timeline.png)

La CI tambi√©n incluye dos pr√°cticas m√°s, seg√∫n Kent Beck y la comunidad XP:

1. TBD: los desarrolladores trabajan sobre el trunk (= master, main o mainline) en peque√±os lotes y fusionan su trabajo regularmente en un trunk compartido, al menos una vez al d√≠a, en lugar de trabajar en ramas de features de larga duraci√≥n.

2. TDD: La creaci√≥n de suites de pruebas unitarias automatizadas mantenibles es compleja. Una manera de resolver este problema es practicar el TDD. Los desarrolladores escriben pruebas automatizadas que inicialmente fallan, antes de implementar el c√≥digo que hace que las pruebas pasen.


### Timeline no TBD

![Background image](img/non-tbd-timeline.png)

[TBD vs no TBD](https://dora.dev/devops-capabilities/technical/trunk-based-development/)


## Controversia de CI

- Pr√°cticas de CI son controvertidas
  - Dividir _features_ grandes en pasos peque√±os
  - Lleva m√°s tiempo completar las _features_ grandes

- Si los cambios son peque√±os
  - Desarrollo + Entrega m√°s r√°pidos y estables
  - Las ramas son de corta duraci√≥n
  - Los desarrolladores reciben comentarios peri√≥dicos sobre el impacto de su trabajo en el sistema en conjunto
  - M√°s f√°cil y r√°pido detectar, clasificar y solucionar problemas

CI es el paso previo a la CD

Las pr√°cticas de CI se consideran a veces controvertidas.

- Requiere que los desarrolladores dividan las caracter√≠sticas grandes y otros cambios en pasos incrementales m√°s peque√±os que se puedan integrar con frecuencia en el trunk. Esto es un cambio para los desarrolladores que no est√°n acostumbrados a trabajar de esta manera.
- Adem√°s, cuando los equipos cambian a usar pasos peque√±os, puede llevar m√°s tiempo completar las caracter√≠sticas grandes.

Cuando los cambios son en lotes peque√±os (y autocontenidos):

- El proceso de CI da como resultado un desarrollo y entrega m√°s r√°pidos y estables
- Las ramas en las que viven los cambios son de corta duraci√≥n
- Tambi√©n garantiza que los desarrolladores reciban comentarios peri√≥dicos sobre el impacto de su trabajo en el sistema en su conjunto, tanto de otros desarrolladores, probadores y clientes, como de las pruebas automatizadas de rendimiento y seguridad.
- Esto hace m√°s f√°cil y r√°pido detectar, clasificar y solucionar problemas.

A pesar de las objeciones, ayudar a los equipos de desarrollo de software a implementar la CI deber√≠a ser la prioridad n√∫mero uno para comenzar el viaje hacia la CD.


![Background image](img/plutarco.png)

## Entrega Continua


![Background image](img/plutarco.png)

**_Lo entreg√≥ todo al fuego,_**
**_que no hace distinci√≥n_**

**&emsp; Plutarco**


## Entrega Continua

![Background image](img/deploy-button.png)

Se hace CD cuando:

- Software desplegable en cualquier momento
- Equipo prioriza mantener el software desplegable
- Tras un cambio, cualquiera puede saber r√°pidamente si el sistema est√° listo para producci√≥n
- Se puede desplegar con un click cualquier versi√≥n del software en cualquier entorno


![Background image](img/dilbert-software-finished.png)

### Beneficios de CD

- Despliegues con riesgo reducido
- Progreso cre√≠ble: ¬øqui√©n garantiza el _done_? ¬øque est√© en producci√≥n? ¬øque lo digan los desarrolladores?
- Feedback de los usuarios: reduce el riesgo de construir algo in√∫til

Cuanto antes te des cuenta...


#### Cuanto antes te des cuenta, mejor

![Background image](img/dilbert-user-requirements.png)


### C√≥mo implementar CD

- Automatizar el build, las pruebas y el despliegue
- Trunk-based development
  - n¬∫ ramas activas < 3
  - ramas y forks con vida corta (< 1 d√≠a)
  - pocos locks del c√≥digo (merge conflicts, freezes, etc.)
- Shift-left de la seguridad
- **Arquitectura poco acoplada**
- Dejar a cada equipo elegir sus herramientas
- Control de versiones de configuraciones y scripts de despliegue
- **Gesti√≥n de cambios en la base de datos**: _fixtures_

>[!NOTE]
>Arquitectura poco acoplada: permite a los equipos probar y desplegar sus aplicaciones de forma independiente, sin necesidad de orquestaci√≥n con otros servicios. Permite trabajar de forma independiente sin depender de otros equipos para obtener soporte y servicios.

Gesti√≥n de cambios en la base de datos: almacenar los cambios de la BD como scripts en el control de versiones (y gestionar estos cambios de la misma manera que los cambios de la aplicaci√≥n en producci√≥n)


### Errores comunes al implementar CD

- Creer que CD implica hacer despliegues frecuentes
- No hacer cambios en las capacidades t√©cnicas necesarias para hacer CD
- Centrarse solo en herramientas y patrones (v.g. deployment pipeline)
- No hacer CD porque no se puede hacer CDEP


### Transformaci√≥n

![Background image](img/cd-j-curve.png)

>[!NOTE]
>Al principio de la curva de transformaci√≥n se logran victorias r√°pidas.

En una etapa inicial de mejora, la automatizaci√≥n ayuda a progresar de un bajo rendimiento a un rendimiento medio.

En el punto m√°s bajo de la curva, la automatizaci√≥n aumenta los requisitos de prueba, que se tratan manualmente. La gran cantidad de deuda t√©cnica bloquea el progreso.

Al salir de la curva, la deuda t√©cnica y el incremento de complejidad ralentizan el trabajo, provocando a√±adir controles manuales y m√°s capas de procesos tras cada cambio.

S√≥lo en la parte alta de la curva, el trabajo de mejora realizado logra un rendimiento alto.
<!-- Source: branching.md -->
# BRANCHING PATTERNS


## SCV: Source Code Versioning

![](img/scv-vcs-scm.png)

**VCS: Version Control Systems** &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; **SCM: Source Code Management**

¬øPara qu√© sirven?

- Rastrear cambios y restaurar versiones anteriores del software
- Gestionar y coordinar el c√≥digo fuente en equipos de desarrollo de software
- Seguimiento de varias l√≠neas de trabajo y ayudar a fusionar l√≠neas

>[!NOTE]
>El c√≥digo fuente es un activo vital para cualquier equipo de desarrollo de software. Las herramientas de gesti√≥n de c√≥digo fuente sirven para rastrear cambios, lo que facilita la recreaci√≥n de versiones anteriores del software y ver c√≥mo se desarrolla con el tiempo.

Tambi√©n sirven para coordinar a un equipo de programadores que trabajan en un c√≥digo base com√∫n. Al registrar los cambios que cada desarrollador realiza, estos sistemas pueden hacer un seguimiento de m√∫ltiples l√≠neas de trabajo al mismo tiempo y ayudar a los desarrolladores a fusionar estas l√≠neas de trabajo.


### SCV centralizado o distribuido

![Background image](img/scv-centralized.png)
![Background image](img/scv-distributed.png)


**¬øGit es descentralidado o centralizado?**

![](img/git-logo.png)


### ¬øGit descentralizado?

![Background image](img/centr-decentr@2x.png)

Repo central con la **verdad**

- **origin** centraliza pull/push

¬øHacer pull de otros repos?

- Subequipos: Alice & Bob, Alice & David, David & Clair
- Alice define _remotes_ `bob` y `david`, etc.


### Git: repositorios remotos

| üìô | Definiciones |
----:|:----
**fork** |  Una copia de un repositorio en el que se puede trabajar de forma independiente (te haces propietario)
**clone** | Copia de un repo remoto (**origin**) en la m√°quina local, para trabajar independientemente (pero no eres propietario)
**origin** | Nombre para referirse al repositorio remoto del que se clon√≥ un repo local
**upstream** | Nombre para referirse al repositorio original desde el que se forke√≥ un repo


![Background image](img/scv-branching.png)

## Workflow y **branching patterns**

- Patrones para ayudar a manejar la divisi√≥n del desarrollo en l√≠neas de trabajo que se dividen y fusionan (split/merge) en ramas (branch)
- No son est√°ndares definitivos
- Dependen de la estructura social del equipo y sus pr√°cticas habituales

>[!NOTE]
>Se han desarrollado varios patrones para ayudar a manejar la divisi√≥n del desarrollo en l√≠neas de trabajo que se dividen y fusionan en el flujo de trabajo (workflow) de los equipos de desarrollo de software.

Estos patrones no son est√°ndares definitivos. El flujo de trabajo del desarrollo de software depende en gran medida del contexto, especialmente de la estructura social del equipo y otras pr√°cticas que el equipo siga.


![Background image](img/git-workflow.png)

### Patrones de workflow habituales

- [GitHub flow](https://docs.github.com/es/get-started/quickstart/github-flow): para todo (no s√≥lo desarrollo)
- [Git Flow](https://nvie.com/posts/a-successful-git-branching-model/): para desarrollo [web], centrado en _releases_
  - [Git Flow considered harmful](https://www.endoflineblog.com/gitflow-considered-harmful)
- [OneFlow](https://www.endoflineblog.com/oneflow-a-git-branching-model-and-workflow): ramas de vida corta
- [Gitlab flow](https://about.gitlab.com/topics/version-control/what-is-gitlab-flow/): menos _tagging_ y _merging_


![Background image](img/scv-branching.png)

## Conceptos de branching

**source branching** = crear una copia del c√≥digo fuente para registrar en ella todos los cambios de forma independiente

- ¬øQu√© es un **commit**?
- ¬øQu√© es **staging**?
- ¬øQu√© es una **rama**?
- ¬øQu√© es un **head**?
- ¬øQu√© es un **fork**?

>[!NOTE]
>Git permite cambiar la historia a base de commits. Otros SCV no.

Git representa los commits como snapshots, no como diffs. Eso hace que sea m√°s r√°pido, pero ocupa m√°s espacio.

Staging es a√±adir ficheros al pr√≥ximo commit.


| üìô | Definiciones |
----:|:----
**commit** | Conjunto de cambios en el c√≥digo fuente que se registra en el repositorio
**branch** | Una secuencia de commits
**head** | √öltimo commit de una rama
**staging** | Preparar los cambios para el pr√≥ximo commit

¬°Cuidado! Confusi√≥n terminol√≥gica sobre qu√© es una rama

- ¬øCuando se clona un repo, se crea una nueva rama?
- Distintos DVCS: Mercurial _branch_ $\neq$ Git _branch_ $\approx$ Mercurial _bookmark_

>[!NOTE]
>En Mercurial, cada rama requiere su propio directorio
En Git, cada rama es un puntero a un commit, todo dentro de un √∫nico directorio

En Mercurial, cambiar de rama es cambiar de directorio
En Git, cambiar de rama es cambiar el contenido del directorio (haciendo checkout)

Mercurial tiene named branches (permanentes) para ramas dentro de un mismo directorio
En Git las ramas son temporales y se borran cuando se fusionan


| üìô | Definiciones |
----:|:----
**branching** | Crear una copia del c√≥digo fuente para registrar en ella todos los cambios en el c√≥digo de forma independiente
**merge** | Integrar los cambios de una rama en otra
**codeline** | Secuencia particular de versiones de una base de c√≥digo (_codebase_)
**clone** | Clonar un repo es hacer un _checkout_ de una rama en una nueva _codeline_
**mainline** | Una rama √∫nica compartida por todos que sirve como estado actual del producto

En cada commit, pasar pruebas autom√°ticas para asegurar que la rama no tiene defectos


### Codeline

- Cada desarrollador tiene (en cuanto hace cambios locales) al menos una **codeline personal** en la _working copy_ de su equipo local
- En un DVCS como git...
  - ...cuando se clona un repo git, se hace un checkout de main y se actualiza algo, se obtiene una **codeline nueva**, aunque no se hagan commits
  - ...obtenemos ramas adicionales cada vez que clonamos un repositorio; las ramas pueden ser **locales** o **remotas**


### Merge vs rebase vs cherry-pick

![Conflicts](img/merge-rebase-cherry-b.png)


### Tutorial recomendado

JJ Merelo: [Aprende Git](https://github.com/JJ/aprende-git)


## Patrones habituales de Workflow


### 1. Git Flow

M√°s estructurado y utiliza diferentes tipos de ramas para diversas etapas del desarrollo.
No es muy adecuado para hacer CD o CDEP.

1. La rama `develop` es la base para nuevas caracter√≠sticas.
2. Se crean ramas `feature` de caracter√≠sticas y se fusionan de nuevo en `develop`.
3. Se crean ramas `release` para preparar las versiones a entregar.
4. Una vez probadas, las ramas se fusionan en `master` y `develop`.
5. Las ramas `hotfix` corrigen problemas en producci√≥n y se fusionan en `master` y `develop`.
6. Cuando los cambios en `develop` son estables, se fusionan en `master` y se le asigna una _tag_ con el n√∫mero de _release_.

Alex Hyett: [Comparativa GitHub flow vs GitFlow](https://www.alexhyett.com/git-flow-github-flow/)


![Background image](img/gitflow.png)


![Background image](imd/../img/mermaid-diagram-github-flow.png)

### 2. GitHub Flow

Enfoque sencillo para CD/CDEP. No para caracter√≠sticas complejas con muchos desarrolladores en paralelo.
Despliegues deben estar automatizados.

1. Una rama `main` o `master` como rama principal.
2. Se trabaja en ramas aparte para nuevas caracter√≠sticas.
3. Las correcciones r√°pidas se tratan como caracter√≠sticas.
4. Se crean _pull requests_ para discutir y revisar los cambios.
5. Una vez aprobados, los cambios se fusionan en la rama `main`.
6. Todo en la rama `main` est√° listo para ser desplegado.

Scott Chacon: [GitHub Flow](https://scottchacon.com/2011/08/31/github-flow/)


#### Git Flow vs GitHub Flow

|                         | Git Flow                                      | GitHub Flow                            |
| ----------------------- | ---------------------------------------------| ---------------------------------------|
| **Adaptabilidad**       | Puede ser excesivo para proyectos peque√±os   | M√°s simple y adaptable para proyectos √°giles     |
| **Releases**            | Varias versiones en producci√≥n               | Una versi√≥n en producci√≥n              |
| **Colaboraci√≥n**        | √ânfasis en separaci√≥n de roles               | Colaboraci√≥n m√°s sencilla y continua   |
| **Despliegue**          | Potencialmente m√°s lento (muchas ramas)      | M√°s r√°pido (CI se hace en main)        |
| **Automatizaci√≥n**      | Se beneficia de herramientas espec√≠ficas     | Requiere despliegue autom√°tico         |


### 3. GitLab Flow

Versi√≥n simplificada y m√°s orientada a la entrega continua

1. Se trabaja con ramas `feature` y `fix` para nuevas caracter√≠sticas y correcciones de errores.
2. Se crean _merge requests_ para revisar y discutir los cambios.
3. Una vez aprobados, se fusionan en `main`.
4. Se crean ramas `production` y `stable` para producci√≥n.
5. Define un conjunto de [buenas pr√°cticas](https://about.gitlab.com/topics/version-control/what-are-gitlab-flow-best-practices/).

NOTA: Los merge requests se llaman _pull requests_ en git


### Ejercicio recomendado

[Tutorial de `git-flow`](https://github.com/uca-virtualizacion/devops/blob/main/gitflow.md)


## Tipos de patrones

Martin Fowler: [Patterns for managing source code branching](https://martinfowler.com/articles/branching-patterns.html)

- Patrones de **integraci√≥n**: c√≥mo combinar el trabajo de varios desarrolladores
- Patrones de **entrega**: c√≥mo llevar una _codebase_ a producci√≥n
- Otros patrones de base
  - [Source branching](https://martinfowler.com/articles/branching-patterns.html#source-branching)
  - [Mainline](https://martinfowler.com/articles/branching-patterns.html#mainline)
  - [Healthy branch](https://martinfowler.com/articles/branching-patterns.html#healthy-branch)


## Patrones de integraci√≥n


## Patrones de integraci√≥n

- [Mainline integration](https://martinfowler.com/articles/branching-patterns.html#mainline-integration): Los desarrolladores integran su trabajo haciendo _pull_ de la mainline, fusionando y haciendo _push_ a la mainline que debe quedar saludable.
- [Feature branching](https://martinfowler.com/articles/branching-patterns.html#feature-branching): Una rama propia para todo el trabajo de cada caracter√≠stica e integrarla en la mainline al completar la caracter√≠stica.
- [Continuous integration](https://martinfowler.com/articles/branching-patterns.html#continuous-integration): Los desarrolladores integran su trabajo en la mainline tan pronto como tienen un commit saludable que compartir (normalmente < 1 d√≠a).
- [Pre-integration review](https://martinfowler.com/articles/branching-patterns.html#reviewed-commits): pull/merge requests

Martin Fowler: _Patterns for managing source code branching_
[Integration patterns](https://martinfowler.com/articles/branching-patterns.html#integration-patterns)

En GitHub Flow:

- los desarrolladores trabajan con Feature branching

- la Mainline integration usa PR (Pre-integration review)

- no hay Continuous integration


### Mainline integration

Checkout:

![](img/mainline-integration-checkout.png)

- Pull + push
- Mainline: _healthy branch_
- Conflictos sem√°nticos: _self-testing code_


### Mainline integration

Update:

![](img/mainline-integration-other-update.png)

- Pull + push
- Mainline: _healthy branch_
- Conflictos sem√°nticos: _self-testing code_


### Mainline integration

Pull:

![](img/mainline-integration-pull.png)

- Pull + push
- Mainline: _healthy branch_
- Conflictos sem√°nticos: _self-testing code_


### Mainline integration

Merge:

![](img/mainline-integration-fuse.png)

- Pull + push
- Mainline: _healthy branch_
- Conflictos sem√°nticos: _self-testing code_


### Mainline integration

Integrate:

![](img/mainline-integration-integrate.png)

- Pull + push
- Mainline: _healthy branch_
- Conflictos sem√°nticos: _self-testing code_


**¬øCu√°l debe ser la frecuencia de integraci√≥n?**


[Frecuencia de integraci√≥n](https://martinfowler.com/articles/branching-patterns.html#integration-frequency)

![Background image](img/integration-frequency.png)

**Cantidad de trabajo**

>[!NOTE]
>M1 es un push de alg√∫n otro desarrollador

El merge final de violeta es m√°s complicado


[Frecuencia de integraci√≥n](https://martinfowler.com/articles/branching-patterns.html#integration-frequency)

![Background image](img/integration-frequency-conflict.png)

**Riesgo de conflictos**

¬øCu√°ndo se detecta un posible conflicto en 1er. commit?

- baja frecuencia: merge final `S1` y `V1`
- alta frecuencia: primer merge


### Feature branching

Branch:

![](img/fb-start.png)


### Feature branching

Pull:

![](img/fb-pull.png)

- Llegan otros commits a la mainline

>[!NOTE]
>Hacer pull "de vez en cuando". ¬øCada cu√°nto?


### Feature branching

Integrate:

![](img/fb-integrate.png)

- Mainline integration


**¬øEs compatible el _feature branching_ con la integraci√≥n continua?**


[Feature branching y CI](https://martinfowler.com/articles/branching-patterns.html#ComparingFeatureBranchingAndContinuousIntegration)

- Depende de la frecuencia de integraci√≥n
- Depende del tiempo que se tarda en completar una caracter√≠stica
- Continuous integration (CI)
  - Todos los commits de una caracter√≠stica van juntos
  - El c√≥digo de cada caracter√≠stica siempre est√° en el producto
  - Feature flags para switch on/off
- Feature branching
  - No obliga a mantener ramas saludables
  - Puede disuadir de hacer refactoring (que introducen conflictos)


[Feature Branching y Open Source](https://martinfowler.com/articles/branching-patterns.html#FeatureBranchingAndOpenSource)

En proyectos open-source:

- Una o pocas personas como mantenedores y programadores
- Un grupo m√°s grande de contribuidores (desconocidos para el mantenedor)
- Calidad de c√≥digo discutible
- Incertidumbre total sobre el tiempo que dedicar√°n los contribuidores y su eficacia

En proyectos comerciales:

- Un equipo de personas conocidas y comprometidas a tiempo completo
- Expectativas fiables de la calidad del c√≥digo y la capacidad de entrega
- Empleados remunerados y mayor control sobre el tiempo dedicado, est√°ndares de codificaci√≥n y h√°bitos del grupo


**En proyectos open source, ¬øqu√© se adapta mejor, _feature branching_ o CI?**

>[!NOTE]
>Una estrategia de branching para equipos comerciales no tiene por qu√© ser la misma que en el mundo open-source.

CI es casi imposible para los contribuidores ocasionales al open-source, pero es una alternativa realista para el trabajo comercial.


## Patrones de entrega continua

![](img/mainline-release.png)

Martin Fowler: _Patterns for managing source code branching_
[The path from mainline to production release](https://martinfowler.com/articles/branching-patterns.html#path-to-production)


## Entrega desde la _mainline_

- [Release branch](https://martinfowler.com/articles/branching-patterns.html#release-branch): Una rama que solo acepta los commits ya aceptados para una versi√≥n estable del producto, lista para su release
- [Maturity branch](https://martinfowler.com/articles/branching-patterns.html#maturity-branch): Una rama cuyo head marca la versi√≥n para producci√≥n de la codebase
- [Environment branch](https://martinfowler.com/articles/branching-patterns.html#environment-branch): Contiene los commits necesarios para reconfigurar el producto para un entorno nuevo de ejecuci√≥n
- [Hotfix branch](https://martinfowler.com/articles/branching-patterns.html#hotfix-branch):  Cada rama que captura el trabajo necesario para corregir un defecto urgente de producci√≥n
- [Release train](https://martinfowler.com/articles/branching-patterns.html#release-train): Releases a intervalos regulares; desarrolladores eligen la suya
- [Release-ready mainline](https://martinfowler.com/articles/branching-patterns.html#release-ready-mainline): Mantener la mainline lo suficientemente saludable como para que el head pueda ir directamente a producci√≥n


### Release branch

![Background image](img/apply-to-release.png)

- [Release branch](https://martinfowler.com/articles/branching-patterns.html#release-branch): √∫nica
- Maturity branch
- Environment branch
- Hotfix branch
- Release train
- Release-ready mainline

>[!NOTE]
>Las nuevas features no se a√±aden a la release, sino a la mainline

Los desarrolladores solo se preocupan de la release para arreglar defectos urgentes (hotfixes)

Los hotfixes se aplican a la release y se fusionan en la mainline (¬°Recordarlo!)

Release: expl√≠cita en Git Flow; no necesaria en GitHub Flow


### Release branch

![Background image](img/multi-release.png)

- [Release branch](https://martinfowler.com/articles/branching-patterns.html#release-branch): m√∫ltiples
- Maturity branch
- Environment branch
- Hotfix branch
- Release train
- Release-ready mainline

>[!NOTE]
>Algunos productos tendr√°n muchas versiones presentes en producci√≥n.

El software que se ejecuta en el equipo de los clientes solo se actualizar√° cuando el cliente lo desee.

Muchos clientes son reacios a actualizar por nuevas caracter√≠sticas.

Pero siguen queriendo correcciones de errores, especialmente si implican problemas de seguridad.

Se mantienen abiertas varias ramas para cada release y se aplican los hotfixes seg√∫n sea necesario.

Hotfix: expl√≠cita en Git Flow; no necesaria en GitHub Flow


### Hotfix branch

![Background image](img/hotfix-branch.png)

- Release branch
- Maturity branch
- Environment branch
- [Hotfix branch](https://martinfowler.com/articles/branching-patterns.html#hotfix-branch)
- Release train
- Release-ready mainline

>[!NOTE]
>Aplicar hotfix primero a producci√≥n y luego a la mainline
Tambi√©n a la release branch si hay una abierta


### Hotfix branch

![Background image](img/hotfix-rb.png)

- Release branch
- Maturity branch
- Environment branch
- [Hotfix branch](https://martinfowler.com/articles/branching-patterns.html#hotfix-branch): con release branch
- Release train
- Release-ready mainline

>[!NOTE]
>Si el equipo usa release branches, los cambios del hotfix se puede hacer en la release branch y se hace una nueva release.

Esto convierte la antigua release branch en una hotfix branch.


### Hotfix branch

![Background image](img/hotfix-on-mainline.png)

- Release branch
- Maturity branch
- Environment branch
- [Hotfix branch](https://martinfowler.com/articles/branching-patterns.html#hotfix-branch): desde mainline
- Release train
- Release-ready mainline

>[!NOTE]
>Si se hace CD, se pueden lanzar hotfixes directamente desde la mainline.
Se lanza la hotfix desde el √∫ltimo commit, no desde del √∫ltimo released.

La nueva release se etiqueta como 2.2.1, ya que si un equipo trabaja as√≠ es probable que M4 y M5 no incluyan nuevas caracter√≠sticas. Si lo hacen, entonces el hotfix se incluir√° en una release 2.3.

No permitir commits en la mainline hasta que el hotfix est√© completado.


### Maturity branch

![Background image](img/production-branch.png)

- Release branch
- [Maturity branch](https://martinfowler.com/articles/branching-patterns.html#maturity-branch)
- Environment branch
- Hotfix branch
- Release train
- Release-ready mainline

>[!NOTE]
>Los de QA quieren conocer la versi√≥n √∫ltima del producto

Una vez que el codebase llegue a un cierto nivel de preparaci√≥n, se copia a una rama espec√≠fica: v.g. production

A veces basta con usar bien el tagging en vez de una maturity branch separada

En Git Flow, la rama master es la maturity branch para producci√≥n


### Environment branch

![Background image](img/environment-branch.png)

- Release branch
- Maturity branch
- [Environment branch](https://martinfowler.com/articles/branching-patterns.html#environment-branch)
- Hotfix branch
- Release train
- Release-ready mainline

>[!NOTE]
>Cambios en una URL, en la configuraci√≥n de acceso a la BD, ubicaci√≥n del sistema de mensajer√≠a, etc.


### Release train

![Background image](img/release-train-multi.png)

- Release branch
- Maturity branch
- Environment branch
- Hotfix branch
- [Release train](https://martinfowler.com/articles/branching-patterns.html#release-train): m√∫ltiples
- Release-ready mainline

Release train:
- variaci√≥n: trenes futuros
- releases regulares desde la mainline


### Release train

![Background image](img/release-train-future.png)

- Release branch
- Maturity branch
- Environment branch
- Hotfix branch
- [Release train](https://martinfowler.com/articles/branching-patterns.html#release-train): trenes futuros
- Release-ready mainline

Release train:
- variaci√≥n: trenes futuros
- releases regulares desde la mainline


### Release train

![Background image](img/release-train-mainline.png)

- Release branch
- Maturity branch
- Environment branch
- Hotfix branch
- [Release train](https://martinfowler.com/articles/branching-patterns.html#release-train): desde mainline
- Release-ready mainline

Release train:
- variaci√≥n: trenes futuros
- releases regulares desde la mainline


### Release-ready mainline

![Background image](img/mainline-release.png)

- Release branch
- Maturity branch
- Environment branch
- Hotfix branch
- Release train
- [Release-ready mainline](https://martinfowler.com/articles/branching-patterns.html#release-ready-mainline)

- En GitFlow hay release branches, luego no hay una release-ready mainline;
- En GitHub Flow solo hay una versi√≥n en producci√≥n, que se integra como Release-ready mainline
<!-- Source: scv/scv-01.md -->
# Sistema de Control de Versiones (SCV)

![](img/Git-logo.png)


## SCV

### ¬øQu√© es un Sistema de Control de Versiones (SCV)?

Un SCV, en ingl√©s *Version Control System* (VCS), registra los cambios realizados en un conjunto de archivos a lo largo del tiempo.

Permite recuperar versiones espec√≠ficas de esos archivos, √∫til para el trabajo colaborativo y para mantener un historial de cambios.

### Repositorio

Lugar donde se almacenan los archivos de un proyecto, junto con el historial de cambios.

Puede estar ubicado localmente en la m√°quina del usuario o de forma remota en un servidor.


## SCV: Source Code Versioning

![](img/scv-vcs-scm.png)

**VCS: Version Control Systems** &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; **SCM: Source Code Management**

¬øPara qu√© sirven?

- Rastrear cambios y restaurar versiones anteriores del software
- Gestionar y coordinar el c√≥digo fuente en equipos de desarrollo de software
- Seguimiento de varias l√≠neas de trabajo y ayudar a fusionar l√≠neas

>[!NOTE]
>El c√≥digo fuente es un activo vital para cualquier equipo de desarrollo de software. Las herramientas de gesti√≥n de c√≥digo fuente sirven para rastrear cambios, lo que facilita la recreaci√≥n de versiones anteriores del software y ver c√≥mo se desarrolla con el tiempo.

Tambi√©n sirven para coordinar a un equipo de programadores que trabajan en un c√≥digo base com√∫n. Al registrar los cambios que cada desarrollador realiza, estos sistemas pueden hacer un seguimiento de m√∫ltiples l√≠neas de trabajo al mismo tiempo y ayudar a los desarrolladores a fusionar estas l√≠neas de trabajo.


## Herramientas SCV

- **Subversion (SVN)**: sistema **centralizado** de control de versiones
  - Un solo repositorio central que almacena todas las versiones
  - Los usuarios deben estar conectados al repositorio central para trabajar

- **Git**: sistema **distribuido** de control de versiones
  - Cada usuario tiene una copia completa del repositorio
  - Los usuarios pueden trabajar de forma independiente sin necesidad de una conexi√≥n constante a un servidor central

Git fue creado por Linus Torvalds en 2005 y se ha convertido en uno de los SCV m√°s populares y ampliamente utilizados en la comunidad de desarrollo de software.


## Plataformas en la nube

Alojamiento de repositorios (y m√°s cosas) en la nube como GitHub, GitLab y Bitbucket.

Permiten a los desarrolladores alojar y colaborar en proyectos de c√≥digo abierto y repositorios p√∫blicos o privados de forma remota.

![](img/GitHub-logo.png) ![](img/gitlab-logo-100.png) ![](img/Bitbucket-Logo-blue.svg)


## GitHub

![Background image](img/GitHub-logo.png)

- Forja donde alojar proyectos software
- Origen en 2008 y adquirido por Microsoft en 2019
- Basado en el SCV distribuido `git`

### Servicios de GitHub

- Code hosting
- Version control
- Releases
- Issues, labels & milestones
- Actions & workflows
- Etc.


## Instalaci√≥n de Git

### Linux

```bash
sudo apt update
sudo apt install git
```

### Windows

Descarga e instala Git desde el sitio web oficial [Git Download](https://git-scm.com/downloads)

### Mac

Descarga e instala Git desde el sitio web oficial [Git for Mac](https://git-scm.com/download/mac) o usando brew:

```bash
brew install git
```


## Trabajando con repositorios

### Inicializar un repositorio local

En caso de que no exista un repositorio local, podemos crear uno con:

```bash
git init
```

- Se crear√° un nuevo repositorio de Git en ese directorio
- Se crea un directorio oculto llamado `.git` que contiene todos los archivos necesarios para el repositorio

Sin embargo, en la mayor√≠a de los casos, clonaremos un repositorio remoto.


### Clonar un repositorio remoto

Al clonar un repositorio remoto, se crea una copia del repositorio en nuestro equipo que debemos sincronizar manualmente.

```bash
git clone <repo>
```

Los repositorios tendr√°n sus propios permisos de lectura y escritura.

Si son privados, necesitareis autenticaros para poder clonarlos.

Vamos a usar un repositorio p√∫blico de Github:

```bash
  git clone https://github.com/sistemas-sw/iiss-git-<curso_actual>.git
```

Donde `<curso_actual>` es el curso actual (por ejemplo, `24-25`).


### Actualizar un repositorio local

Creamos un archivo de texto usando nuestro identificador UCA como nombre `uxxxxxxxx.txt`.

Para agregar el archivo al repositorio local, usamos el comando `git add`:

```bash
git add <file>
```

Podemos a√±adir todos los archivos y directorios nuevos o modificados con:

```bash
git add .
```

Podemos comprobar el estado del repositorio local usando el comando `git status`:

- Archivos nuevos o modificados aparecer√°n en rojo
- Archivos a√±adidos al repositorio aparecer√°n en verde


### Actualizar cambios

Para confirmar los cambios en el repositorio local, usamos el comando `git commit`:

```bash
git commit -m "Mensaje"
```

- El mensaje debe ser descriptivo y debe indicar los cambios realizados
- Al ejecutar `git commit`, se crea un nuevo commit en el repositorio local
- Cada commit tiene un identificador √∫nico que se puede usar para identificarlo


### Sincronizar cambios

Para subir los cambios al repositorio remoto, usamos el comando `git push` (debemos tener permisos de escritura en el repositorio remoto):

```bash
git push
```

Si queremos actualizar nuestro repositorio local con los cambios del repositorio remoto:

```bash
git pull
```


### Comprobar cambios

Para ver las diferencias entre el repositorio local y el repositorio remoto:

```bash
git diff
git diff <file>
```

Para ver el historial de cambios realizados en el repositorio local:

```bash
git log
git log <file>
```

Para ver el historial de cambios realizados en el repositorio remoto:

```bash
git log origin/main
git log origin/main <file>
```


### Deshacer cambios

Para deshacer los cambios realizados en un archivo:

```bash
git checkout <file>
```

Para deshacer los cambios realizados en todos los archivos:

```bash
git checkout .
```

Si queremos deshacer los cambios realizados en un archivo que hemos a√±adido al repositorio:

```bash
git reset HEAD <file>
```

HEAD hace referencia al √∫ltimo commit realizado.


## Trabajando con ramas

Una rama es una l√≠nea de desarrollo independiente que permite trabajar en un conjunto de cambios sin afectar al resto del proyecto.

Las ramas se pueden fusionar entre s√≠ para combinar los cambios realizados en cada una de ellas.

![](img/Git_branch.svg)

[Ejemplo de ramas en un repositorio de Git](https://www.atlassian.com/git/tutorials/using-branches)


### Crear ramas (i)

Una rama se crea a partir de otra rama existente

![](img/Git_branch_new.png)

- `git branch` muestra las ramas existentes
- Podemos ver la rama actual con `git branch` y con `git status`.


### Crear ramas (ii)

Para crear una nueva rama a partir de la rama actual:

```bash
git branch <nombre_de_la_rama>
```

Para crear una nueva rama a partir de la rama actual y cambiar a ella:

```bash
git checkout -b <nombre_de_la_rama>
```


### Checkout y push de ramas

Cambiar de rama:

```bash
git checkout <nombre_de_la_rama>
```

Subir una rama al repositorio remoto:

```bash
git push origin <nombre_de_la_rama>
```


### Eliminar ramas

Eliminar una rama del repositorio local (seguir√° existiendo en el repositorio remoto):

```bash
git branch -d <nombre_de_la_rama>
```

Eliminar una rama del repositorio remoto (seguir√° existiendo en el repositorio local):

```bash
git push origin --delete <nombre_de_la_rama>
```


### Stash de ramas

Guardar/esconder los cambios realizados en la rama actual para poder cambiar de rama sin tener que hacer un commit

`git stash` - guardar los cambios realizados en la rama actual

`git stash pop` - recuperar los cambios guardados

`git stash list` - ver los cambios guardados

`git stash drop` - eliminar los cambios guardados


### Fusionar ramas (i)

Siempre que se fusionan dos ramas, se crea en la rama actual un nuevo commit que contiene los cambios de ambas ramas:

![](img/branch-merge.png)

[Ejemplo de fusi√≥n de ramas en un repositorio de Git](https://www.atlassian.com/es/git/tutorials/using-branches/git-merge)


### Fusionar ramas (ii)

Para fusionar una rama con la rama actual:

```bash
git merge <nombre_de_la_rama>
```

- Si no hay conflictos, se fusionar√°n autom√°ticamente
- Si hay conflictos, se mostrar√° un mensaje de error y habr√° que resolverlos manualmente

Para resolver conflictos, se editan los archivos que los contienen y se a√±aden al repositorio con `git add`.

Una vez resueltos los conflictos, se puede fusionar la rama con la rama actual.


### Ejemplo de conflicto entre ramas

1. Crear una rama nueva llamada `prueba1` a partir de la rama actual y cambiar a ella
2. Editar el archivo `uxxxxxxxx.txt` y a√±adir una l√≠nea con el texto `prueba1`
3. A√±adir el archivo al repositorio local y hacer un commit
4. Cambiar a la rama `main`
5. Editar el archivo `uxxxxxxxx.txt` y a√±adir una l√≠nea con el texto `main`
6. A√±adir el archivo al repositorio local y hacer un commit
7. Fusionar la rama `prueba1` con la rama `main`

![](img/conflicto.png)


### Solucionar conflictos entre ramas

Podemos ver los conflictos con `git status`.

Para solucionar el conflicto, editamos el archivo `uxxxxxxxx.txt` y dejamos el contenido que queramos.

Tambi√©n podemos solucionar el conflicto aceptando el contenido de una de las ramas con:

```bash
git checkout --ours <file>
```

```bash
git checkout --theirs <file>
```

Donde `ours` es la rama actual y `theirs` es la rama que estamos fusionando.


### Rebase de ramas (i)

Rebase soluciona el mismo problema que la fusi√≥n de ramas, pero de forma muy distinta:

- `merge` crea un nuevo commit que contiene los cambios de ambas ramas
- `rebase` mueve los commits de una rama a otra

![](img/rebase.png)

[Ejemplo de rebase de ramas en un repositorio de Git](https://www.atlassian.com/es/git/tutorials/merging-vs-rebasing)


### Merge vs rebase vs cherry-pick

![Conflicts](img/merge-rebase-cherry-b.png)


### Rebase de ramas (ii)

Para hacer un rebase de una rama con la rama actual:

```bash
git rebase <nombre_de_la_rama>
```


### Rebase de ramas (iii)

1. Crear una rama llamada `feature_rebase` a partir de la rama actual y cambiar a ella
2. Crea un archivo `feature_rebase.txt`
3. A√±adir el archivo al repositorio local y hacer un commit
4. Cambiar a la rama `main`
5. A√±adir un archivo `main.txt`
6. A√±adir el archivo al repositorio local y hacer un commit
7. Cambiar a la rama `feature_rebase`
8. Hacer un rebase de la rama `feature_rebase` con la rama `main`
9. Comprobar el historial de cambios con `git log`


### Rebase de ramas (iv)

- Rebase actualiza el historial de cambios de una rama con el historial de cambios de otra rama.
- Es muy √∫til para mantener el historial de cambios de una rama "limpio" y ordenado.

**Suele usarse en ramas de desarrollo que se fusionan con la rama principal del proyecto.**

Rebase es una operaci√≥n muy potente, pero tambi√©n muy peligrosa:

- Si se hace mal, puede provocar que se pierdan commits
- Siempre que se haga un rebase, se debe hacer en una rama que no se haya compartido con nadie


## Archivos especiales de git

Archivo `.gitignore`

- Indica los archivos y directorios que no queremos a√±adir al repositorio
- Para a√±adir una excepci√≥n a un archivo o directorio ignorado, se puede forzar su inclusi√≥n con `!`
- Para a√±adir un archivo o directorio ignorado, se puede forzar su inclusi√≥n con `git add -f`

Archivo `.gitkeep`:

- Git no permite a√±adir directorios vac√≠os al repositorio
- Para a√±adir un directorio vac√≠o, se crea un archivo `.gitkeep` dentro del directorio


## Otras herramientas para trabajar con Git

Herramientas con interfaz gr√°fica:

- [SourceTree](https://www.sourcetreeapp.com/)
- [Git for Windows](https://gitforwindows.org/)
- [GitHub Desktop](https://desktop.github.com/)
- [Git Extensions](https://gitextensions.github.io/)
- [TortoiseGit](https://tortoisegit.org/)

Los IDEs m√°s populares (VS Code, JetBrains', etc.) tienen integraci√≥n con Git


### Vocabulario git (1)

| üìô | Repositorios |
----:|:----
**fork** |  Una copia de un repositorio en el que se puede trabajar de forma independiente (te haces propietario)
**clone** | Copia de un repo remoto (**origin**) en la m√°quina local, para trabajar independientemente (pero no eres propietario)
**origin** | Nombre para referirse al repositorio remoto del que se clon√≥ un repo local
**upstream** | Nombre para referirse al repositorio original desde el que se forke√≥ un repo
**commit** | Conjunto de cambios en el c√≥digo fuente que se registra en el repo
**checkout** | Cambiar de rama activa en el repo local


### Vocabulario git (2)

| üìô | Ramas |
----:|:----
**branch** | Una secuencia de commits
**head** | √öltimo commit de una rama
**stage** | Cambios preparados para el pr√≥ximo commit
**push/pull ** | Sincronizar commits con/desde el repositorio remoto/local
**merge ** | Fusionar una rama con otra
**rebase ** | Mover commits de una rama a otra
**stash ** | Dejar a un lado (guardar) los cambios en la rama actual


## Tarea

1. Crear un repositorio en GitHub
2. Clonar el repositorio en local
3. A√±adir cambios a la rama `main` a√±adiendo un directorio vac√≠o y un archivo `.gitignore` para ignorar todos los archivos markdown excepto el `README.md` y el `LICENSE.md`
4. Crea una rama `feature` y a√±ade cambios a esa rama
5. Crear dos ramas desde main, a√±adir cambios, fusionarlas en main y eliminarlas. Una de las ramas debe contener conflictos a resolver
6. Hacer rebase de la rama `feature` con la rama `main`
7. A√±adir un cambio m√°s a la rama `feature`
8. Fusionar la rama `feature` con la rama `main`
9. Subir los cambios al repositorio remoto
10. Eliminar la rama `feature`


### Tutorial recomendado

JJ Merelo: [Aprende Git](https://github.com/JJ/aprende-git)
<!-- Source: terraform/terraform-01.md -->
# Terraform para Infraestructura Docker

![](img/Terraform_PrimaryLogo_Color_RGB.svg)


## Introducci√≥n a Terraform (I)

Terraform es una herramienta de c√≥digo abierto que permite automatizar la implementaci√≥n y gesti√≥n de infraestructura como c√≥digo (IaC).

IaC es una metodolog√≠a que permite definir y administrar la infraestructura de una aplicaci√≥n utilizando archivos de configuraci√≥n en lugar de configuraciones manuales.

- Automatizaci√≥n: automatiza la creaci√≥n, configuraci√≥n y gesti√≥n de recursos de infraestructura, lo que ahorra tiempo y reduce errores

- Declarativo: se decribe el estado de la infraestructura en lugar de escribir scripts

- Multiplataforma: compatible con una variedad de proveedores de nube y tecnolog√≠as: AWS, Azure, Google Cloud, Kubernetes, Docker...

- Colaboraci√≥n y Replicabilidad: archivos de configuraci√≥n legibles y versionables


## Introducci√≥n a Terraform (II)

![](img/terraform_architecture.avif)

- Creaci√≥n de los archivos Terraform (IaC)
- Plan: Vista previa de los cambios que Terraform realizar√° para que coincidan con tu configuraci√≥n
- Apply: Se aplican los cambios planificados


## Introducci√≥n a Terraform (III)

### Uso de Terraform para Infraestructura Docker

Terraform permite crear y gestionar una infraestructura Docker completa: contenedores, im√°genes, redes y vol√∫menes.

En esta pr√°ctica, se utilizar√° Terraform para crear y gestionar una infraestructura Docker.

![](img/docker-010.png)


## Instalaci√≥n de Terraform (I)

https://developer.hashicorp.com/terraform/downloads

### Instalaci√≥n (Linux)

```bash
sudo apt update
sudo apt install terraform
```

### Instalaci√≥n (MacOS)

```bash
brew tap hashicorp/tap
brew install hashicorp/tap/terraform
```


## Instalaci√≥n de Terraform (II)

https://developer.hashicorp.com/terraform/downloads

### Instalaci√≥n (Windows)

Instalaci√≥n con [chocolatey](https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli).

```shell
choco install terraform
```


## Creaci√≥n de Infraestructura Docker con Terraform (I)

Primero, crea un directorio de trabajo para tus pr√°cticas de Terraform.

```bash
mkdir mi_proyecto_terraform
cd mi_proyecto_terraform
```

Dentro del directorio de trabajo, inicializa un proyecto Terraform con el siguiente comando:

```bash
terraform init
```


## Creaci√≥n de Infraestructura Docker con Terraform (II)

El comando `terraform init` se utiliza para inicializar un directorio de trabajo de Terraform. Cuando ejecutas este comando, Terraform realiza varias tareas importantes:

- Descarga de **proveedores**: Terraform identifica y descarga los proveedores de recursos espec√≠ficos que se utilizar√°n en tu configuraci√≥n. Por ejemplo, si est√°s creando una infraestructura Docker, Terraform descargar√° el proveedor de Docker.

- Inicializaci√≥n del **estado**: El estado es un archivo que almacena informaci√≥n sobre la infraestructura gestionada.

- Validaci√≥n de la **configuraci√≥n**: Terraform verifica la sintaxis y la validez de tus archivos de configuraci√≥n.


## Creaci√≥n de Infraestructura Docker con Terraform (III)

### Estado de Terraform

El estado de Terraform almacena informaci√≥n sobre la infraestructura que est√°s gestionando, incluidos los recursos que Terraform ha creado y su estado actual.

- Permite comprender la diferencia entre la infraestructura deseada y la existente
- Se almacena de forma segura y puede ser compartido entre miembros del equipo
- Puede contener informaci√≥n sensible, como contrase√±as o claves secretas

A continuaci√≥n se muestra un ejemplo de estado de Terraform:
- Informaci√≥n sobre el recurso `docker_container` llamado `my_container`
- Incluye la imagen utilizada
- Incluye los puertos mapeados


### Ejemplo de Estado de Terraform

```plaintext
# terraform.tfstate
{
  "version": 4,
  "terraform_version": "1.0.5",
  "serial": 1,
  "lineage": "4d4a0f63-80d7-4b48-9a92-09c4909d5e6b",
  "outputs": {},
  "resources": [
    {
      "module": "",
      "mode": "managed",
      "type": "docker_container",
      "name": "my_container",
      "provider": "provider[docker]",
      "instances": [
        {
          "schema_version": 2,
          "attributes": {
            "command": null,
            "image": "nginx:latest",
            "name": "mi-contenedor",
            "networking_type": "bridge,container:mi-contenedor",
            "ports": [
              {
                "external": 8080,
                "internal": 80,
                "ip": "0.0.0.0",
                "type": "tcp"
              }
            ],
            "volumes": []
          },
          "private": "hidden sensitive data"
        }
      ]
    }
  ]
}
```


## Creaci√≥n de archivos de configuraci√≥n (I)


### Ejemplo de configuraci√≥n `nginx.tf`

```ruby
terraform {
  required_providers {
    docker = {
      source = "kreuzwerker/docker"
      version = "~> 3.0.1"
    }
  }
}

provider "docker" {}
#¬†Para Windows, a√±adir:  host = "npipe:////.//pipe//docker_engine"

resource "docker_image" "nginx" {
  name         = "nginx:latest"
  keep_locally = false
}

resource "docker_container" "nginx" {
  image = docker_image.nginx.image_id
  name  = "practica_terraform"
  ports {
    internal = 80
    external = 8000
  }
}
```


## Creaci√≥n de archivos de configuraci√≥n (II)

```ruby
terraform {
  required_providers {
    docker = {
      source = "kreuzwerker/docker"
      version = "~> 3.0.1"
    }
  }
}
```

- El bloque `terraform` define la configuraci√≥n de Terraform. En este caso, hemos especificado el proveedor de Docker que se utilizar√° y su versi√≥n (igual o superior a 3.0.1 pero inferior a 4.0.0).
- Terraform instala los proveedores del Registro de Terraform ([Terraform Registry](https://registry.terraform.io/)) de forma predeterminada


## Creaci√≥n de archivos de configuraci√≥n (III)

```ruby
provider "docker" {}
#¬†Para Windows, a√±adir:  host = "npipe:////.//pipe//docker_engine"
```

- El bloque `provider` especifica la configuraci√≥n del proveedor Docker. En este caso, no se especifica ninguna configuraci√≥n adicional


## Creaci√≥n de archivos de configuraci√≥n (IV)

```ruby
resource "docker_image" "nginx" {
  name         = "nginx:latest"
  keep_locally = false
}
```

- El bloque `resource` crea una imagen Docker a partir de otra imagen indicada (en este caso _nginx_). La imagen se descargar√° autom√°ticamente si no existe localmente
- El prefijo del tipo se relaciona con el nombre del proveedor. Terraform gestiona el recurso `docker_image` con el proveedor docker.
- El tipo y el nombre del recurso forman un ID √∫nico para el recurso (`docker_image.nginx`).


## Creaci√≥n de archivos de configuraci√≥n (V)

```ruby
resource "docker_container" "nginx" {
  image = docker_image.nginx.image_id
  name  = "practicas"
  ports {
    internal = 80
    external = 8000
  }
}
```

- Los bloques de recursos contienen argumentos para configurar los recursos. El bloque `docker_container` crea un contenedor Docker utilizando la imagen anterior
- Adem√°s, realiza un mapeo de puertos para exponer el puerto `80` interno como el puerto `8000` externamente

Ejecutar `terraform init` para inicializar el directorio de trabajo con la nueva configuraci√≥n.


## Formateo y validaci√≥n

Es recomendable utilizar un formato consistente en los archivos de configuraci√≥n.

El comando `terraform fmt` actualiza autom√°ticamente las configuraciones en el directorio actual para mejorar la legibilidad y la consistencia.

```bash
terraform fmt
```

Terraform imprimir√° los nombres de los archivos que modific√≥. Si no se modific√≥ ning√∫n archivo, no se imprimir√° nada.

Puede comprobarse si la configuraci√≥n es sint√°cticamente v√°lida utilizando el comando:

```bash
terraform validate
```


## Planificaci√≥n de la creaci√≥n de la infraestructura

Antes de aplicar cambios, es una buena pr√°ctica realizar una planificaci√≥n para comprender qu√© recursos se crear√°n o modificar√°n y c√≥mo afectar√°n a la infraestructura.

La planificaci√≥n da una vista previa de los cambios que Terraform realizar√°.

Para planificar la creaci√≥n de la infraestructura, utiliza el siguiente comando:

```bash
terraform plan
```

Terraform escanear√° tus archivos de configuraci√≥n, evaluar√° la infraestructura actual y generar√° un plan detallado de los cambios propuestos.


## Creaci√≥n de la infraestructura (I)

Para crear la infraestructura, aplica los archivos de configuraci√≥n del directorio actual mediante:

```bash
terraform apply
```

- Terraform escanear√° tus archivos de configuraci√≥n, evaluar√° la infraestructura actual, generar√° un plan detallado de los cambios propuestos y lo aplicar√°.
- Esto incluir√° la creaci√≥n de nuevos recursos, actualizaciones de recursos existentes y la destrucci√≥n de recursos obsoletos si los hay.

La informaci√≥n mostrada es similar a la de `terraform plan`.


## Creaci√≥n de la infraestructura (II)

```plaintext
  # docker_image.nginx will be created
  + resource "docker_image" "nginx" {
      + id           = (known after apply)
      + keep_locally = false
      + latest       = (known after apply)
      + name         = "nginx:latest"
      + output       = (known after apply)
    }

Plan: 2 to add, 0 to change, 0 to destroy.
```

- La salida con `+` indica que se crear√° este recurso
- Debajo, se muestran los atributos que se definir√°n para el recurso

Terraform solicitar√° confirmaci√≥n antes de aplicar los cambios (`yes` para continuar).


## Creaci√≥n de la infraestructura (III)

Una vez creada la infraestructura, Terraform mostrar√° un resumen de los recursos creados.

Podemos comprobar los contenedores creados con `docker ps` y acceder a la aplicaci√≥n en http://localhost:8000.

El archivo de estado de Terraform (`terrafor.tfstate`) se habr√° creado/actualizado con la informaci√≥n de los recursos creados.

Estado actual de la infraestructura:
```bash
terraform show
```

Listar los recursos actuales:

```bash
terraform state list
```


## Modificaci√≥n de la infraestructura

Modifica el archivo de configuraci√≥n para cambiar el puerto externo a 8001:

```ruby
resource "docker_container" "nginx" {
  image = docker_image.nginx.image_id
  name  = "practicas"
  ports {
    internal = 80
    external = 8001
  }
}
```

Aplica los cambios con `terraform apply` y comprueba que el contenedor se ha recreado con el nuevo puerto http://localhost:8001.

- El prefijo `-`/`+` significa que Terraform destruir√° y volver√° a crear el recurso
- Terraform puede actualizar algunos atributos (prefijo `~`), pero cambiar el puerto de un contenedor requiere recrearlo


## Destrucci√≥n de la infraestructura

Cuando ya no necesites ciertos recursos o quieras eliminar completamente la infraestructura, puedes utilizar el siguiente comando para destruirla:

```bash
terraform destroy
```

Se mostrar√° un plan de destrucci√≥n similar al de `terraform plan` y se solicitar√° confirmaci√≥n antes de aplicar los cambios.

Tras confirmar, se eliminar√°n los recursos de la infraestructura.

En el caso de Docker, los contenedores se eliminar√°n y las im√°genes se eliminar√°n si no se utilizan en otros contenedores.


## Aplicaci√≥n de Variables de Entorno (I)

Las variables de Terraform permiten escribir configuraciones din√°micas y flexibles.

Las variables se pueden definir con un bloque `variable` en el mismo archivo de configuraci√≥n (`nginx.tf`) o en un archivo separado `variables.tf`:

```ruby
variable "container_name" {
  description = "Value of the name for the Docker container"
  type        = string
  default     = "NginxContainer"
}
```

- El nombre de la variable es `container_name`
- La descripci√≥n es opcional, pero es una buena pr√°ctica incluirla
- El tipo de variable es `string`
- El valor predeterminado es `NginxContainer`


## Aplicaci√≥n de Variables de Entorno (II)

Para utilizar la variable en el archivo de configuraci√≥n, se utiliza la sintaxis `${var.container_name}`:

```ruby
resource "docker_container" "nginx" {
  image = docker_image.nginx.image_id
  name  = "${var.container_name}"
  ports {
    internal = 80
    external = 8001
  }
}
```

Aplica los cambios con `terraform apply` y comprueba que el contenedor se ha recreado con el nuevo nombre.


## Aplicaci√≥n de Variables de Entorno (III)

Si lo que queremos es a√±adir variables de entorno al contenedor Docker, podemos utilizar el atributo `env`:

```ruby
resource "docker_container" "nginx" {
  image = docker_image.nginx.image_id
  name  = "${var.container_name}"
  ports {
    internal = 80
    external = 8001
  }
  env = [
    "MY_ENV_VAR=my_env_value"
  ]
}
```


## Vol√∫menes de Docker

Para a√±adir un volumen de Docker, usa el recurso docker_volume en la configuraci√≥n:

```ruby
resource "docker_volume" "my_volume" {
  name = "my_volume"
}
```

Para utilizar el volumen en un contenedor, se utiliza el bloque `volumes`:

```ruby
resource "docker_container" "nginx" {
  ...
  volumes {
    volume_name = docker_volume.my_volume.name
    container_path = "/usr/share/nginx/html"
  }
}
```

Cada volumen se define indicando el nombre del volumen y la ruta de montaje dentro del contenedor.


## Redes de Docker

Para a√±adir una red de Docker, usa el recurso docker_network en la configuraci√≥n:

```ruby
resource "docker_network" "my_network" {
  name = "my_network"
}
```

Para utilizar la red en un contenedor, se utiliza el bloque `networks_advanced`:

```ruby
resource "docker_container" "nginx" {
  ...
  networks_advanced {
    name = docker_network.my_network.name
  }
}
```


## Tarea Entregable

1. Crea una infraestructura Docker personalizada utilizando Terraform.
2. La infraestructura debe contener un contenedor con una aplicaci√≥n Wordpress y otro contenedor con una base de datos MariaDB.
3. Deben estar conectados a una red Docker.
4. Debe existir un volumen para almacenar los datos de la base de datos y que no se eliminen al destruir la infraestructura.
5. Deben usarse variables de entorno para configurar la aplicaci√≥n Wordpress.
6. Debe existir un archivo de configuraci√≥n `variables.tf` con las variables de entorno.
<!-- Source: jenkins/jenkins-01.md -->
# CI/CD con Jenkins


![Background image](img/cicd-jenkins.png)

# Integraci√≥n y Entrega Continuas


## Continous Integration / Continuous Delivery

![Background image](img/cicd_side.png)

- Continuous integration (CI)
- Continuous delivery (CD)
- Continuous deployment

Cada proceso tiene su propio **pipeline**

>[!NOTE]
>Cada uno de estos procesos tiene su propio pipeline


### Pipeline de CI

![CI pipeline](img/ci-pipeline.png)

>[!NOTE]
>CI es la pr√°ctica de construir y probar las aplicaciones en cada nueva versi√≥n.


### Pipeline de CD

![CD pipeline](img/cd-pipeline.png)

CD a√±ade pruebas autom√°ticas y despliegue autom√°tico al proceso de CI.

Gracias a CD, el software entregado debe funcionar siempre.

Todos los cambios que se incorporan en un _build_ pueden formar parte de un candidato a _release_.

Antiguamente, los cambios peque√±os sol√≠an tener que esperar a que se completaran otros muchos antes de ser empaquetados en una release. Siguiendo ese modelo, se supon√≠a que el software era incorrecto hasta que era validado por profesionales de QA. Todas las pruebas se realizaban despu√©s del desarrollo, la responsabilidad de la calidad reca√≠a exclusivamente en el equipo de QA.


### Continuous Deployment

![CDEP pipeline](img/cdep-pipeline.png)

>[!NOTE]
>El despliegue continuo es la pr√°ctica de desplegar autom√°ticamente el software en producci√≥n despu√©s de cada cambio.

La entrega es manual, el despliegue es autom√°tico.


| üìô | Definiciones |
----:|:----
**Build**   | compilar y ensamblar el c√≥digo fuente en formato ejecutable o en un conjunto de artefactos para un entorno espec√≠fico
**Pipeline**   | conjunto automatizado y secuencial de procesos para ejecutar tareas espec√≠ficas
**Staging** | entorno de prueba que replica el entorno de producci√≥n para realizar pruebas finales (con usuarios) antes del despliegue
**Artefacto** | resultado del _build_. Pueden ser binarios ejecutables, bibliotecas, paquetes de instalaci√≥n, etc., necesarios para ejecutar la aplicaci√≥n
**Release** | una versi√≥n espec√≠fica y completa de una aplicaci√≥n o software que se considera lista para ser distribuida y utilizada por los usuarios finales


# Jenkins

![](img/jenkins.svg)


## ¬øQu√© es Jenkins?

- Jenkins es un servidor de automatizaci√≥n de c√≥digo abierto escrito en Java.

- Ayuda a automatizar el proceso de compilaci√≥n, prueba e implementaci√≥n de software.

- Se puede instalar a trav√©s de paquetes nativos, Docker o incluso ejecutarlo como una aplicaci√≥n independiente.

- Se puede integrar con una gran cantidad de herramientas de desarrollo y pruebas a trav√©s de complementos.


## Descargar e instalar Jenkins en Docker

- Hay varias im√°genes de Docker de Jenkins disponibles.

- Utiliza la imagen oficial recomendada https://hub.docker.com/r/jenkins/jenkins/ del repositorio Docker Hub. Esta imagen contiene la versi√≥n actual LTS de Jenkin

- Sin embargo, esta imagen no contiene Docker CLI, ni incluye plugins de Blue Ocean que se utilizan con frecuencia

- Vamos a realizar una instalaci√≥n personalizada

Como requisito previo, debes tener instalado Docker en su sistema

https://www.jenkins.io/doc/book/installing/docker/


### Im√°genes de Docker

```bash
docker pull jenkins/jenkins
docker pull docker:dind
```

- La imagen dind (Docker in Docker) es una imagen de Docker que contiene Docker
- Dind se utiliza para ejecutar comandos de Docker dentro de los nodos de Jenkins

### Red

Crear una red de tipo bridge en Docker:

```bash
docker network create jenkins
```


## Docker in Docker (dind)

![Background image](img/docker-dind-min.png)

Crea un contenedor hijo dentro de otro contenedor Docker

- Contenedores e im√°genes disponibles en el contenedor hijo
- Acceso [privilegiado](https://docs.docker.com/engine/reference/run/#runtime-privilege-and-linux-capabilities) al host (¬°seguridad!)


### Instalaci√≥n dind:

```bash
docker run --privileged -d --name dind-test docker:dind
docker exec -it dind-test /bin/sh
docker pull ubuntu
docker images
mkdir test && cd test
vi Dockerfile
docker build -t test-image .
```

**Dockerfile**:

```Dockerfile
FROM ubuntu:18.04
RUN apt-get update && \
    apt-get -qy full-upgrade && \
    apt-get install -qy curl && \
    apt-get install -qy curl && \
    curl -sSL https://get.docker.com/ | sh
```


### Docker in Docker (macOS y Linux) (comando)

Para ejecutar comandos de Docker dentro de los nodos de Jenkins, ejecuta la imagen de Docker `docker:dind` utilizando el siguiente comando:

```bash
docker run --name jenkins-docker --rm --detach \
  --privileged --network jenkins --network-alias docker \
  --env DOCKER_TLS_CERTDIR=/certs \
  --volume jenkins-docker-certs:/certs/client \
  --volume jenkins-data:/var/jenkins_home \
  --publish 2376:2376 \
  docker:dind --storage-driver overlay2
```


### Docker in Docker (Windows) (comando)

En Windows, ejecuta el siguiente comando para ejecutar la imagen de Docker `docker:dind`:

```bash
docker run --name jenkins-docker --rm --detach ^
  --privileged --network jenkins --network-alias docker ^
  --env DOCKER_TLS_CERTDIR=/certs ^
  --volume jenkins-docker-certs:/certs/client ^
  --volume jenkins-data:/var/jenkins_home ^
  --publish 2376:2376 ^
  docker:dind
```


### Docker in Docker

```bash
docker run --name jenkins-docker # Nombre del contenedor
  --rm # Elimina el contenedor cuando se para
  -d #¬†Ejecuta el contenedor en segundo plano
  --privileged #¬†Otorga privilegios necesarios para Dind
  --network jenkins #¬†Conecta el contenedor a la red jenkins
  --network-alias docker
  #¬†Contenedor de Dind disponible como el nombre de host 'docker'
  --env DOCKER_TLS_CERTDIR=/certs #¬†Habilita TLS dentro del contenedor
  -v jenkins-docker-certs:/certs/client #¬†Certificados TLS
  -v jenkins-data:/var/jenkins_home #¬†Datos de Jenkins
  -p 2376:2376 #¬†Puertos
  docker:dind #¬†Imagen de Docker
  --storage-driver overlay2 #¬†Controlador de almacenamiento a utilizar
```


### Dockerfile

Personaliza la imagen oficial de Jenkins de Docker usando un Dockerfile:

```bash
FROM jenkins/jenkins
USER root
RUN apt-get update && apt-get install -y lsb-release
RUN curl -fsSLo /usr/share/keyrings/docker-archive-keyring.asc \
  https://download.docker.com/linux/debian/gpg
RUN echo "deb [arch=$(dpkg --print-architecture) \
  signed-by=/usr/share/keyrings/docker-archive-keyring.asc] \
  https://download.docker.com/linux/debian \
  $(lsb_release -cs) stable" > /etc/apt/sources.list.d/docker.list
RUN apt-get update && apt-get install -y docker-ce-cli
USER jenkins
RUN jenkins-plugin-cli --plugins "blueocean docker-workflow"
```


### Construir imagen

Construye una nueva imagen de Docker a partir de este Dockerfile y asigna a la imagen un nombre significativo como `myjenkins-blueocean`:

```bash
docker build -t myjenkins-blueocean .
```


## Ejecutar Jenkins

Ejecuta la imagen de Jenkins personalizada con el siguiente comando:

```bash
docker run --name jenkins-blueocean --restart=on-failure --detach \
  --network jenkins --env DOCKER_HOST=tcp://docker:2376 \
  --env DOCKER_CERT_PATH=/certs/client --env DOCKER_TLS_VERIFY=1 \
  --publish 8080:8080 --publish 50000:50000 \
  --volume jenkins-data:/var/jenkins_home \
  --volume jenkins-docker-certs:/certs/client:ro \
  myjenkins-blueocean
```

Opcionalmente, puede a√±adirse `--env JAVA_OPTS="-Dorg.jenkinsci.plugins.durabletask.BourneShellScript.LAUNCH_DIAGNOSTICS=true" \` justo antes de la √∫ltima l√≠nea para que Jenkins muestre los logs de los scripts.


### Ejecutar Jenkins (explicaci√≥n)

```bash
docker run
  --name jenkins-blueocean # Nombre del contenedor
  --restart=on-failure # Reinicia el contenedor si falla
  -d #¬†Ejecuta el contenedor en segundo plano
  --network jenkins #¬†Conecta el contenedor a la red jenkins
  --env DOCKER_HOST=tcp://docker:2376 #¬†Direcci√≥n del host de Docker
  --env DOCKER_CERT_PATH=/certs/client #¬†Ruta certificados TLS
  --env DOCKER_TLS_VERIFY=1 #¬†Habilita verificaci√≥n de TLS
  -p 8080:8080 -p 50000:50000 #¬†Puertos
  -v jenkins-data:/var/jenkins_home #¬†Datos de Jenkins
  -v jenkins-docker-certs:/certs/client:ro #¬†Certificados TLS
  myjenkins-blueocean #¬†Especifica la imagen de Docker a utilizar
```


## Accediendo al contenedor de Docker

Para acceder al contenedor de Docker, usa `docker exec` junto con el nombre del contenedor de Docker y `bash`:

```bash
docker exec -it jenkins-blueocean bash
```

Para acceder a los logs del contenedor de Docker, usa `docker logs`:

```bash
docker logs jenkins-blueocean
```

En caso de haber usado otro nombre para el contenedor, sustituye `jenkins-blueocean` por el nombre que hayas usado.


## Asistente de configuraci√≥n

Despu√©s de instalar y ejecutar Jenkins podemos a un asistente de configuraci√≥n a trav√©s de la interfaz web:

http://localhost:8080

Este asistente te gu√≠a para:
  - Desbloquear Jenkins
  - Instalar plugins
  - Crear el primer usuario administrador


## Crear un Pipeline (I)

Un pipeline es un conjunto de pasos que Jenkins ejecuta para compilar, probar y entregar software.

Un pipeline se define en un archivo de texto llamado `Jenkinsfile`.

1. Haz clic en **Nueva tarea** en el men√∫ de la izquierda

2. Introduce un nombre para la tarea y selecciona **Pipeline**

3. Haz clic en **OK**


## Crear un Pipeline (II)

1. En la secci√≥n **Definici√≥n de Pipeline**, selecciona **Pipeline script**

2. Introduce el siguiente c√≥digo en el editor:

```groovy
  pipeline { // Declaraci√≥n de pipeline
      agent any // Agente que ejecuta el pipeline
      stages { // Declaraci√≥n de etapas
          stage('Stage 1') { // Declaraci√≥n de etapa
              steps { // Declaraci√≥n de pasos
                  echo 'Hello world!' // Paso
              }
          }
      }
  }
```

3. Haz clic en **Guardar**


## Ejecutar un Pipeline

1. Haz clic en **Construir ahora** en el men√∫ de la izquierda

2. Haz clic en el n√∫mero de compilaci√≥n en la columna **Construcciones**

3. En la secci√≥n, **Console Output**, podemos ver la salida del pipeline

Debido a que personalizamos la imagen de Jenkins, tambi√©n podemos usar la interfaz **Open Blue Ocean** (men√∫ de la izquierda).


## Jenkinsfile

- Contiene la definici√≥n de un pipeline
- Est√° escrito en el lenguaje de programaci√≥n Groovy
- Se puede almacenar en un repositorio de c√≥digo fuente como GitHub y Bitbucket

```groovy
pipeline {
    agent {
        // Agente que ejecuta el pipeline (puede ser de Jenkins o de Docker)
    }
    environment {
        // Variables de entorno
    }
    stages {
        // Declaraci√≥n de etapas
    }
}
```


### Agentes (Jenkins)

```groovy
pipeline {
    agent {
        label 'label' // Nombre del agente de Jenkins
    }
}
```

Podemos ver los agentes de Jenkins disponibles en **Administrar Jenkins** > **Administrar nodos**.

Tambi√©n podemos indicar que el pipeline se ejecute en cualquier agente disponible:

```groovy
pipeline {
    agent any
}
```


### Agentes (Docker)

```groovy
pipeline {
    agent {
        docker {
            image 'image'
            args 'args'
        }
    }
}
```

- `image` es el nombre de la imagen de Docker.
- `args` son los argumentos que se pasan a la imagen de Docker.

Tambi√©n se puede usar un archivo Dockerfile que se encuentre en el repositorio:

```groovy
pipeline {
    agent { dockerfile true }
}
```


### Variables de entorno

Las variables de entorno se definen de la siguiente manera:

```groovy

pipeline {
    environment {
        key = 'value'
    }
}
```

- `key` es el nombre de la variable de entorno
- `value` es el valor de la variable de entorno


### Etapas

```groovy
pipeline {
    stages {
        stage('Stage 1') {
            steps {
                // Pasos de la etapa
            }
        }
    }
}
```

- Una etapa es una colecci√≥n de pasos
  - Las etapas se ejecutan secuencialmente
  - Aunque hay opciones para ejecutarlas en paralelo
- Un paso es una acci√≥n que se ejecuta en un agente
  - Los pasos se ejecutan secuencialmente
  - Se usa `sh` para ejecutar comandos de shell


## Pipeline from SCM

Escribir y mantener pipelines complejas dentro del √°rea de texto del Script en la p√°gina de configuraci√≥n de la Pipeline en la interfaz cl√°sica de Jenkins puede ser complicado.

La alternativa para facilitar este proceso es escribir tu Jenkinsfile en un IDE y luego subirlo al control de c√≥digo fuente.


### Crear Pipeline from SCM

1. Crea una nueva pipeline y selecciona **Pipeline script from SCM** en la secci√≥n **Definici√≥n de Pipeline**
2. En **SCM**, selecciona **Git**
3. En **Repository URL**, introduce la URL del repo y las credenciales:

   - **Kind**: Username with password
   - **Username**: nombre de usuario del repositorio
   - **Password**: Token de Acceso Personal (PAT)
   - **ID**: Nombre de la credencial

4. En **Script Path**, introduce el path del archivo Jenkinsfile
5. Haz clic en **Guardar**


## Pipeline para desplegar aplicaci√≥n React

Vamos a crear un pipeline para desplegar una aplicaci√≥n React en un contenedor Docker:
https://www.jenkins.io/doc/tutorials/build-a-node-js-and-react-app-with-npm/

Como requisito previo, debes publicar dos puertos adicionales en el contenedor Dind para Jenkins (jenkins-docker):

`--publish 3000:3000 --publish 5000:5000`


### Ejemplo: Pipeline para desplegar aplicaci√≥n React (I)

1. Crear fork del repositorio que contiene la aplicaci√≥n: https://github.com/jenkins-docs/simple-node-js-react-npm-app
2. Clonamos el repositorio en nuestro equipo
3. Creamos un archivo `Jenkinsfile` en el directorio ra√≠z del repositorio
4. Creamos un pipeline en Jenkins con la opci√≥n **Pipeline script from SCM** y la siguiente configuraci√≥n:
   - **SCM**: Git
   - **Repository URL**: URL del repositorio
   - **Credentials**: No indicar credenciales (el repositorio ser√° p√∫blico)
   - **Script Path**: Jenkinsfile
   - **Branches to build**: */master


### Ejemplo: Pipeline para desplegar aplicaci√≥n React (II)

Incluimos el siguiente c√≥digo en el archivo `Jenkinsfile` y lo subimos al repositorio.

```groovy
pipeline {
    agent {
        docker {
            image 'node:20.10.0-alpine3.18' // Imagen de Docker
            args '-p 3000:3000' // Puertos
        }
    }
    stages {
        stage('Build') {
            steps {
                sh 'npm install' // Instalar dependencias
            }
        }
    }
}
```


### Ejemplo: Pipeline para desplegar aplicaci√≥n React (III)

Volvamos a Jenkins y ejecutemos el pipeline.

1. Haz clic en **Construir ahora** en el men√∫ de la izquierda
2. Puedes ver el progreso del pipeline en la interfaz de usuario de Jenkins

Es posible que debas esperar varios minutos para que se complete esta primera ejecuci√≥n

Despu√©s de clonar tu repositorio local, `Jenkins`:

- Coloca el proyecto en la cola para ejecutarse en el agente
- Descarga la imagen Docker de Node y la ejecuta en un contenedor

Una vez finalizada la ejecuci√≥n, podemos ver el resultado en la interfaz de Jenkins.


### Ejemplo: Pipeline para desplegar aplicaci√≥n React (IV)

Actualizamos el archivo `Jenkinsfile`:

```groovy
  stage('Test') {
      steps {
          sh './jenkins/scripts/test.sh'
      }
  }
```

- El Pipeline debe quedar lo m√°s ordenado posible
- Los pasos de scripting de construcci√≥n m√°s complejos se pueden colocar en archivos separados
- Esto facilita el mantenimiento del Pipeline, especialmente si adquiere m√°s complejidad

Podemos volver a Jenkins y ejecutar el pipeline.


### Ejemplo: Pipeline para desplegar aplicaci√≥n React (V)

Actualizamos el archivo `Jenkinsfile` con una etapa de Entrega/Despliegue:

```groovy
  stage('Deliver') {
      steps {
          sh './jenkins/scripts/deliver.sh'
          input message: 'Finished using the web site? (Click "Proceed" to continue)'
          sh './jenkins/scripts/kill.sh'
      }
  }
```

- El script `deliver.sh` entrega y despliega la aplicaci√≥n en un contenedor Docker (m√°s detalles dentro del script)
- `input message` detiene la ejecuci√≥n y solicita respuesta al usuario


### Ejemplo: Pipeline para desplegar aplicaci√≥n React (VI)

Finalmente, volvemos a ejecutar el pipeline y vemos el resultado en la interfaz de Jenkins.

Si accedemos a http://localhost:3000, podemos ver la aplicaci√≥n React desplegada:

![](img/react.png)

- Si accedemos al contenedor de Jenkins, podemos ver los archivos generados por el pipeline en el directorio `/var/jenkins_home/workspace/<nombre-del-pipeline>`
- Adem√°s, con el comando `docker ps` podemos ver el contenedor creado durante la ejecuci√≥n del pipeline
<!-- Source: gitflow.md -->
# Gitflow

`gitflow` is an auxiliary tool that facilitates the job of working with GitFlow by providing some useful commands.

## Installation

- To install it on [macOS](https://github.com/nvie/gitflow/wiki/Mac-OS-X):

  `brew install git-flow`

- For [Windows](https://github.com/nvie/gitflow/wiki/Windows), GitFlow commands come with [Git SCM](https://git-scm.com/download/win).

  `winget install --id Git.Git -e --source winget`

- For Ubuntu Linux users:

  `apt-get install git-flow`

- [Other Linux](https://github.com/nvie/gitflow/wiki/Linux) distributions

To create, browse and manage an example git repository on GitHub, we'll use the [GitHub CLI](https://github.com/cli/cli) command `gh`. You can install it for [MacOS](https://github.com/cli/cli#macos), [Linux](https://github.com/cli/cli#linux--bsd) or [Windows](https://github.com/cli/cli#windows).

After installig `gh`, you can login to your GitHub account with the command:

```bash
gh auth login
```

This will open a browser window to authenticate you with GitHub and provide it with a one-time token generated by `gh`.

## Main branches

The first step is to understand the roles of the `develop` and `master` branches and how they communicate with the versions of your code. These branches are the most important ones and the key to GitFlow.

![Simple example of branches flow](img/gitflow-01.png)

GitFlow works primarily with two main branches:

- The `master` branch (in blue) stores all the released features until the date, receives the incoming new features from the develop (and only from it), as well as the hotfix changes.

- The `develop` branch (in orange), which has as the only role receiving the changes from the feature branches and centralizing them before any further merge. It‚Äôs here where the teams usually customize the agile process with steps like validations, code review, definitions of done, etc.

## Creating the GitHub Example Repo

Start with the creation of a new GitHub repo to hold the workflow example. For this, go to your GitHub account, create a new repo, and fill it with the following options:

```bash
gh repo create st-git-flow --private --description "A repo to test the Gitflow workflow"
```

Next, create a new folder on your local computer with the same repository name (`st-git-flow``) and then navigate to the folder via the command line.

```bash
mkdir st-git-flow
cd st-git-flow
```

Then, run the following commands, substituting your repository URL:

```bash
echo "# Hello World, GitFlow!" >> index.md
git init
git add .
git commit -m "first commit"
git branch -M master
git remote add origin https://github.com/XXXXXX/st-git-flow.git
git push -u origin master
```

- The first command creates a new Markdown file, with a hello world message. After that, you initialize the Git repo, adding all the files as Git files, and committing.
- The two last commands take care of adding the remote origin and pushing the master branch to the remote repo.

The remote origin can be seen right after the repo creation:

```bash
gh repo view
```

Now‚Äôs time to run the git flow init command.

```bash
git flow init
```

When it finishes, this is the output you may see (`ST` is the prefix chosen for the tags):

```text
Which branch should be used for bringing forth production releases?
   - master
Branch name for production releases: [master]
Branch name for "next release" development: [develop]

How to name your supporting branch prefixes?
Feature branches? [feature/]
Release branches? [release/]
Hotfix branches? [hotfix/]
Support branches? [support/]
Version tag prefix? [] ST
```

It creates the master and develop branches, and asks for the respective names of each feature, release, hotfix, and support branches. You can leave them as they are, and press enter until the end except for the version tag prefix.

In order to compare Git Flow to Git, we‚Äôll provide the equivalent Git commands. The equivalent Git command to achieve this is:

>[!NOTE]
>`$ git checkout -b develop master`


![](img/cmd-git-01.png)

Whenever a developer is going to start a new feature, the `feature` branch must be created from the `develop`. This is the branch that hosts the _next release_ development.

Some team‚Äôs Git administrators even block the possibility of generating new branches from the master branch for security reasons. However, `gitflow` doesn‚Äôt push the develop branch to the remote origin. This is something you must do manually:

```bash
git push -u origin develop
```

This is the output:

```text
Total 0 (delta 0), reused 0 (delta 0), pack-reused 0
remote:
remote: Create a pull request for 'develop' on GitHub by visiting:
remote:      https://github.com/XXXXXX/st-git-flow/pull/new/develop
remote:
To https://github.com/XXXXXX/st-git-flow.git
 * [new branch]      develop -> develop
branch 'develop' set up to track 'origin/develop'.
```

## The Feature Branches

Pay attention to the two new feature branches below:

![Diagram with two new feature branches](img/gitflow-02.png)

There‚Äôs no right due date for a task; it can take one day or two months to complete. It‚Äôs up to the team to decide the maximum time they‚Äôre going to need for any feature.

Feature #2, for example, was started before #1, and finished first, too. Not just this, it has finished in the middle of task #1. For GitFlow, it doesn‚Äôt matter how many features you‚Äôre developing at the same time; the flow guarantees that they‚Äôll get to the `develop` and, in the next release, to the `master`.

If you merge feature #2, for example, and some breaking changes were introduced (i.e., if it adds code that conflicts with the code being developed in feature #1), then feature #1‚Äôs merge will fail.

In this type of situation, which is very common by the way, it‚Äôs normal to have the developers talking to each other when merge fixing, to analyze if what one has done is going to break the code of the other.

Create your first feature branch with this command:

```bash
git flow feature start ST-TASK01
```

And this is the result:

```text
Switched to a new branch 'feature/ST-TASK01'

Summary of actions:
- A new branch 'feature/ST-TASK01' was created, based on 'develop'
- You are now on branch 'feature/ST-TASK01'

Now, start committing on your feature. When done, use:

     git flow feature finish ST-TASK01
```

Without `gitflow`, this would be the command to achieve the same:

>[!NOTE]
>`$ git checkout -b feature/ST-TASK01 develop`


![](img/cmd-git-02.png)

It‚Äôs also a best practice to use tag prefixes in your feature branch names, in order to identify them among the others. Some tracking tools (like Confluence's Jira), use that information to keep track of the correlated branches of your repositories.

Since you‚Äôre on the branch, you may perform all the needed code changes, and commit them. Update the index.md file, for example, with the following content:

```text
# Hello World, GitFlow!
- This is my `task-01` commit.
```

The feature changes are within a new list in which each bullet point contains the respective task id. This way, it‚Äôs going to be easier to track the changes history.

Commit the changes:

```bash
git add .
git commit -m "Updating my feature branch st-task01"
```

Remember, however, that your commits are only local. You must explicitly tell `gitflow` to publish the branch to the remote origin. For this, you just run the command:

```bash
git flow feature publish ST-TASK01
```

Output:

```text
Enumerating objects: 5, done.
Counting objects: 100% (5/5), done.
Delta compression using up to 12 threads
Compressing objects: 100% (2/2), done.
Writing objects: 100% (3/3), 327 bytes | 327.00 KiB/s, done.
Total 3 (delta 0), reused 0 (delta 0), pack-reused 0
remote:
remote: Create a pull request for 'feature/ST-TASK01' on GitHub by visiting:
remote:      https://github.com/XXXXXX/st-git-flow/pull/new/feature/ST-TASK01
remote:
To https://github.com/XXXXXX/st-git-flow.git
 * [new branch]      feature/ST-TASK01 -> feature/ST-TASK01
Already on 'feature/ST-TASK01'
Your branch is up to date with 'origin/feature/ST-TASK01'.

Summary of actions:
- A new remote branch 'feature/ST-TASK01' was created
- The local branch 'feature/ST-TASK01' was configured to track the remote branch
- You are now on branch 'feature/ST-TASK01'
```

Without `gitflow`, you‚Äôd have to run the following:

>[!NOTE]
>`$ git checkout feature/ST-TASK01`
`$ git push origin feature/ST-TASK01`


![](img/cmd-git-03.png)

Now, your branch is live. You can check it directly in the GitHub repo:

```bash
gh browse -b feature/ST-TASK01
```

You can even see a GitHub warning at the top of the page stating that a new branch was recently pushed. It also enables the option to create a new pull request, which is not necessary.

Once you‚Äôre done with the feature development, you might merge it to the develop branch, or do it via `gitflow`:

```bash
git flow feature finish ST-TASK01
```

These are the list of actions taken by this command:

```text
Switched to branch 'develop'
Your branch is up to date with 'origin/develop'.
Updating 121bbb1..6a14536
Fast-forward
 index.md | 1 +
 1 file changed, 1 insertion(+)
Deleted branch feature/ST-TASK01 (was 6a14536).

Summary of actions:
- The feature branch 'feature/ST-TASK01' was merged into 'develop'
- Feature branch 'feature/ST-TASK01' has been removed
- You are now on branch 'develop'
```

And these are the equivalent vanilla Git commands to achieve the same result:

>[!NOTE]
>`$ git checkout develop`
`$ git merge --no-ff feature/MYFEATURE`
`$ git branch -d feature/MYFEATURE`


![](img/cmd-git-04.png)

The `-no-ff` flag prevents the git merge command from performing a fast-forward if Git detects that your HEAD falls short of the commit being merged for security reasons.

Now you have the code merged onto the develop branch. This, however, is not remote yet. GitFlow works basically at a local level; all the decisions to send the changes over the remote repositories depend on you.

Run the command to push things up:

```bash
git push origin --all
```

This command pushes everything that changed locally (branches, tags, etc.) to the remote origin. You‚Äôll make use of it a bit in order to guarantee the `gitflow` changes are always in sync with the remote.

You may now go to GitHub and check the develop contents:

```bash
gh browse -b develop
```

## The Release Branches

The release branch is the branch you‚Äôll create from the develop when you and your team are ready to publish a release.

![Creating a new release branch](img/gitflow-03.png)

After a release branch is created, no more features can be added to it (and this must be a rigorous policy within your team). Of course, things like bug and hot fixes, docs and urgent changes can be discussed and carefully added. It‚Äôs up to the team defining the boundaries.

When everything‚Äôs ready, the branch is merged into the `master`, and a tag is generated. Usually, this process is automated to avoid human errors. The numbering you‚Äôre using for the versions also takes place here.

After that, the `develop` should also receive the release contents, because some important changes (like bug and hot fixes) may be needed by the feature branches. Again, automation would be useful here.

This is an important step of the workflow because many factors can delay the release process, for example, if your company depends on a shipping calendar or the approval of another team. This way, you _release_ the develop branch so the developers may continue to work in the features, while the release code is safe.

This code creates the first release branch:

```bash
git flow release start 0.1.0
```

And here‚Äôs the result:

```text
Switched to a new branch 'release/0.1.0'

Summary of actions:
- A new branch 'release/0.1.0' was created, based on 'develop'
- You are now on branch 'release/0.1.0'

Follow-up actions:
- Bump the version number now!
- Start committing last-minute fixes in preparing your release
- When done, run:

     git flow release finish '0.1.0'
```

Without `gitflow`, you‚Äôd have to run the following command to create the same release branch:

>[!NOTE]
>`$ git checkout -b release/0.1.0 develop`


![](img/cmd-git-05.png)

Next, update the Markdown file with the following:

```text
# Hello World, GitFlow!
- This is my `task-01` commit.
- Our project is going to be released. Version 0.1.0
```

Then, commit the changes:

```bash
git add .
git commit -m "Adding release version"
```

And publish the branch to the remote origin:

```bash
git flow release publish '0.1.0'
```

Output:

```text
Enumerating objects: 5, done.
Counting objects: 100% (5/5), done.
Delta compression using up to 12 threads
Compressing objects: 100% (2/2), done.
Writing objects: 100% (3/3), 363 bytes | 363.00 KiB/s, done.
Total 3 (delta 0), reused 0 (delta 0), pack-reused 0
remote:
remote: Create a pull request for 'release/0.1.0' on GitHub by visiting:
remote:      https://github.com/XXXXXX/st-git-flow/pull/new/release/0.1.0
remote:
To https://github.com/XXXXXX/st-git-flow.git
 * [new branch]      release/0.1.0 -> release/0.1.0
Already on 'release/0.1.0'
Your branch is up to date with 'origin/release/0.1.0'.

Summary of actions:
- A new remote branch 'release/0.1.0' was created
- The local branch 'release/0.1.0' was configured to track the remote branch
- You are now on branch 'release/0.1.0'
```

Here are the equivalent commands for vanilla Git:

>[!NOTE]
>`$ git checkout release/0.1.0`
`$ git push origin release/0.1.0`


![](img/cmd-git-06.png)

This remotely updates the list of branches as well as the warning messages:

```bash
gh browse -b release/0.1.0
```

Finally, release it with the command below (first read the **Note** below):

```bash
git flow release finish '0.1.0'
```

> [!NOTE]
> The `gitflow` release command will prompt 3 editor windows for you to add two merge messages (to `master` and to `develop`) and a tag message. You can choose the editor (e.g. `nano`) by setting the environment variable `export GIT_EDITOR=nano`.

- Content for the 1st editor window (merge to `master`):

```text
Merge branch 'release/0.1.0' to master
# Please enter a commit message to explain why this merge is necessary,
# especially if it merges an updated upstream into a topic branch.
#
# Lines starting with '#' will be ignored, and an empty message aborts
# the commit.
```

- Content for the 2nd editor window (tag message):

```text
Tag message for ST0.1.0
#
# Write a message for tag:
#   ST0.1.0
# Lines starting with '#' will be ignored.
```

- Content for the 3st editor window (merge to `develop`):

```text
Merge branch 'release/0.1.0' to develop
# ...
```

If you don't do it, your default editor is `vim`. After writing each releasing messsage, save it through the shortcut `:x!` ‚Üµ (you first need to press ‚êõ to lose focus on the typing before entering the shortcut).

The release finish command does a lot. Without the power of `gitflow`, you‚Äôd have to go through all these Git commands to get to the same result:

>[!NOTE]
>`$ git checkout master`
`$ git merge --no-ff release/0.1.0`
`$ git tag -a 0.1.0`
`$ git checkout develop`
`$ git merge --no-ff release/0.1.0`
`$ git branch -d release/0.1.0`


![](img/cmd-git-07.png)

This would be the output:

```text
Switched to branch 'master'
Your branch is up to date with 'origin/master'.
Merge made by the 'ort' strategy.
 index.md | 2 ++
 1 file changed, 2 insertions(+)
Switched to branch 'develop'
Your branch is up to date with 'origin/develop'.
Merge made by the 'ort' strategy.
 index.md | 1 +
 1 file changed, 1 insertion(+)
Deleted branch release/0.1.0 (was 6328e0a).

Summary of actions:
- Latest objects have been fetched from 'origin'
- Release branch has been merged into 'master'
- The release was tagged 'ST0.1.0'
- Release branch has been back-merged into 'develop'
- Release branch 'release/0.1.0' has been deleted
```

Here, some interesting things are happening. First, due to `gitflow`‚Äôs local nature, you must push the changes manually to the remote.

The release branch had changes that were merged onto the master; `gitflow` also back-merges the same commits against the develop branch. Plus, a new tag was generated: ST0.1.0. You must push all these updates through the following command:

```bash
git push origin --all
git push origin --tags
```

The tags work as snapshots of your code repo. Whenever you want to consult for a specific spot in time, check the respective tag out.

Another tip would be about the GitHub commits history. If you enter the develop branch at `https://github.com/<user>/st-git-flow/commits/develop`, for example, and click in the link with the number of commits, you can refer to all the changes until now. Enter each commit, and you may see the change‚Äôs diff.

## The Hotfix Branches

Every big company can have emergencies and need urgent fixes. With a bunch of people working in the same code while others try to fix a code snippet to ship to production quickly, the whole scenario can get messy.

![Creating a new hotfix branch](img/gitflow-04.png)

Hotfix branches come to the rescue by allowing the teams to create a new temporary branch upon the master. When done with fixes, you must merge the branch into `master` again, the `develop` branch, and the `release` branch (if there is any).

That‚Äôs why it‚Äôs important to always merge a release branch into the develop, because you can‚Äôt track all the changes, especially if you‚Äôre working with many and large teams.

This is the command to create the first hotfix branch:

```bash
git flow hotfix start ST-TASK01
```

And here you have the output:

```text
Switched to a new branch 'hotfix/ST-TASK01'

Summary of actions:
- A new branch 'hotfix/ST-TASK01' was created, based on 'master'
- You are now on branch 'hotfix/ST-TASK01'

Follow-up actions:
- Bump the version number now!
- Start committing your hot fixes
- When done, run:

     git flow hotfix finish 'ST-TASK01'
```

The equivalent non-`gitflow` command would be:

>[!NOTE]
>`$ git checkout -b hotfix/ST-TASK01 master`


![](img/cmd-git-08.png)

Now, change something in the Markdown file:

```text
# Hello World, GitFlow!
- This is my `task-01` commit.
- Our project is going to be released. Version 0.1.0
- This is my `hotfix` commit.
```

And, again, commit the changes:

```bash
git add .
git commit -m "hotfix changes"
```

Then, send it to the remote origin by running:

```bash
git flow hotfix finish ST-TASK01
```

> [!NOTE]
> You have to write two merge messages (to `master` and to `develop` branches) and a tag message in the opening editor.

- Merge message into `master`:

```text
Merge branch 'hotfix/ST-TASK01'
```

- Tag message:

```text
Tag message for the hotfix 'hotfix/ST-TASK01'
#
# Write a message for tag:
#   STST-TASK01
# Lines starting with '#' will be ignored.
```

- Back-merge message into `develop`:

```text
Merge branch 'hotfix/ST-TASK01' into develop
```

Notice that it‚Äôs not necessary to inform the full name of a branch. If it is a hotfix branch, `gitflow` understands that by the current command you‚Äôre issuing.

The output is:

```text
Switched to branch 'master'
Your branch is up to date with 'origin/master'.
Merge made by the 'ort' strategy.
 index.md | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)
Switched to branch 'develop'
Your branch is up to date with 'origin/develop'.
Merge made by the 'ort' strategy.
 index.md | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)
Deleted branch hotfix/ST-TASK01 (was 4fc4c0e).

Summary of actions:
- Latest objects have been fetched from 'origin'
- Hotfix branch has been merged into 'master'
- The hotfix was tagged 'STST-TASK01'
- Hotfix branch has been back-merged into 'develop'
- Hotfix branch 'hotfix/ST-TASK01' has been deleted
```

The `gitflow`‚Äôs hotfix command is another example of a great shortcut command. It does a lot. These are the Git equivalent commands:

>[!NOTE]
>`$ git checkout master`
`$ git merge --no-ff hotfix/ST-TASK01`
`$ git tag -a ST-TASK01`
`$ git checkout develop`
`$ git merge --no-ff hotfix/ST-TASK01`
`$ git branch -d hotfix/ST-TASK01`


![](img/cmd-git-09.png)

Again, push the master, develop and the tags to the remote origin:

```bash
git push origin --all
git push origin --tags
```

Finally check how the final `index.md` will look.
